{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d2453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T11:28:36.383933Z",
     "start_time": "2025-09-01T11:28:36.381405Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153c7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, hashlib, random, warnings\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9fccb3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T11:28:49.626974Z",
     "start_time": "2025-09-01T11:28:44.920400Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
    "    Dense, Dropout, BatchNormalization, ReLU\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7535ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38504ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMO_MODE = \"7\"\n",
    "CSV_PATH = \"masked_face_dataset.csv\"\n",
    "USE_GENDER = True\n",
    "USE_MBV2   = True\n",
    "MBV2_UNFREEZE_FROM = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec56c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 48\n",
    "IMG_CH   = 1\n",
    "EPOCHS_FULL    = 60\n",
    "EPOCHS_STAGE_A = 40\n",
    "BATCH_SIZE_CNN  = 64\n",
    "BATCH_SIZE_MBV2 = 64\n",
    "MBV2_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db98281b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c7965f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "PIXELS_EXPECTED = IMG_SIZE * IMG_SIZE\n",
    "EMO7 = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
    "EMO5 = [\"angry\",\"fear\",\"happy\",\"sad\",\"surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc47fb2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def parse_pixels(pixels: str):\n",
    "    try:\n",
    "        arr = np.array([int(p) for p in str(pixels).strip().split()], dtype='uint8')\n",
    "        if arr.size != PIXELS_EXPECTED: return np.nan\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2077fe2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_gender(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"m\",\"male\",\"man\",\"0\",\"male(0)\",\"mask_m\"} or s.startswith(\"m\"): return 0\n",
    "    if s in {\"f\",\"female\",\"woman\",\"1\",\"female(1)\",\"mask_f\",\"w\",\"woman(f)\"} or s.startswith((\"f\",\"w\")): return 1\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff99aa7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_ethnicity(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "    if \"asian\" in s: return \"asian\"\n",
    "    if \"black\" in s or \"african\" in s: return \"black\"\n",
    "    if \"latino\" in s or \"hispanic\" in s: return \"latino_hispanic\"\n",
    "    if (\"middle\" in s and \"east\" in s) or \"middle_eastern\" in s: return \"middle_eastern\"\n",
    "    if \"white\" in s: return \"white\"\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7550b4ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def map_to_7_emotions(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s in EMO7 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb71c83",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def map_to_5_emotions(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s == \"disgust\": return \"angry\"\n",
    "    if s == \"neutral\": return np.nan\n",
    "    if s in EMO5: return s\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da1dbca2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def report_counts(name, series):\n",
    "    vc = series.value_counts(dropna=False)\n",
    "    print(f\"\\n{name} distribution:\"); print(vc.to_string()); return vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eac097d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def bar_chart(series, title, out_png, rotate_xticks=True):\n",
    "    plt.figure(figsize=(7,5)); s = series.sort_values(ascending=False)\n",
    "    plt.bar(s.index.astype(str), s.values); plt.title(title); plt.ylabel(\"Count\")\n",
    "    if rotate_xticks: plt.xticks(rotation=30, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"figures\", out_png), dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19494e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV dtypes:\n",
      "pixels               object\n",
      "emotion               int64\n",
      "emotion_label        object\n",
      "age                   int64\n",
      "age_range             int64\n",
      "gender               object\n",
      "ethnicity            object\n",
      "filename             object\n",
      "split                object\n",
      "augmentation_type     int64\n",
      "original_filename    object\n",
      "\n",
      "First 5 rows:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  pixels  emotion emotion_label  age  age_range gender        ethnicity                  filename  split  augmentation_type    original_filename\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   30 26 28 40 58 79 100 116 125 152 138 153 142 143 147 148 109 39 61 96 117 93 80 84 78 89 98 100 98 100 104 105 97 90 92 99 90 63 45 40 40 51 44 35 40 35 29 38 29 28 30 36 45 60 82 100 121 119 140 138 149 141 159 102 43 83 117 98 76 82 77 90 102 120 140 149 147 138 125 115 101 103 106 105 87 65 54 55 55 61 52 42 45 37 29 35 38 40 41 40 39 45 65 84 106 120 128 145 146 151 122 60 67 101 92 75 72 103 98 127 193 199 204 199 190 179 167 157 153 134 112 100 96 90 77 65 63 65 55 45 43 35 27 30 49 50 51 48 42 42 54 68 77 123 116 138 144 127 67 64 92 82 58 64 83 103 97 112 154 139 118 102 107 132 161 179 183 183 166 130 95 76 70 68 66 61 52 46 43 35 30 30 62 61 61 61 57 54 56 62 66 93 116 106 123 68 59 97 104 131 160 141 117 105 114 91 82 93 106 115 120 122 117 110 107 133 157 160 149 129 102 79 74 61 53 50 45 39 35 32 91 88 87 90 90 85 83 84 93 85 111 103 66 50 81 123 159 192 224 186 140 118 141 110 110 125 140 152 160 164 164 160 153 135 115 112 127 136 120 97 80 61 54 54 45 39 35 29 115 111 110 113 113 110 110 111 115 107 106 94 39 82 104 125 170 185 171 144 120 111 128 115 120 134 148 151 146 138 127 119 110 115 120 121 120 116 112 108 86 62 55 57 47 41 39 30 118 115 114 115 114 112 114 119 110 115 111 50 66 108 123 116 134 191 167 142 120 126 125 120 115 129 144 147 144 141 139 136 121 112 101 95 92 94 100 107 92 65 60 63 53 49 48 38 110 110 108 109 110 110 110 108 115 105 96 59 75 95 144 99 143 174 165 133 120 110 105 120 120 142 161 159 149 143 145 149 139 131 129 123 110 105 107 105 90 77 63 55 55 53 45 36 107 106 105 106 108 108 106 105 113 99 73 60 59 80 122 115 175 192 135 94 128 128 99 112 130 148 159 154 146 143 140 135 134 129 128 126 122 127 125 113 81 72 62 57 56 53 45 36 102 101 102 103 105 105 102 100 96 87 50 70 75 118 136 146 128 154 157 133 115 111 103 93 124 144 154 144 133 134 134 129 138 130 126 122 117 116 102 76 69 64 58 55 55 50 42 36 97 97 98 100 101 101 99 97 95 83 39 62 98 164 167 164 130 124 129 116 96 115 123 90 115 139 150 134 121 128 137 139 132 122 123 128 123 111 91 69 58 55 52 50 50 46 40 36 94 94 94 95 97 98 96 95 100 70 40 59 116 170 178 179 166 158 120 92 105 119 108 95 120 132 132 117 111 121 129 127 135 123 129 142 130 106 87 75 56 52 49 47 47 45 41 38 91 90 90 90 93 94 94 92 108 59 52 61 82 66 57 65 49 59 67 68 74 92 109 114 116 105 88 78 84 92 87 75 104 95 104 114 97 74 63 60 59 54 49 47 48 47 42 36 89 86 85 85 87 90 90 90 80 38 60 80 78 50 38 50 55 34 44 55 50 70 96 90 94 75 55 50 55 55 45 33 36 41 54 57 50 52 59 57 59 53 47 48 50 48 38 30 86 84 81 81 83 86 88 89 84 44 57 61 40 33 24 28 20 30 25 30 52 51 53 80 77 65 55 51 47 39 32 31 25 37 45 35 29 47 60 53 55 50 45 47 50 46 33 21 75 105 69 72 97 80 90 84 71 47 57 41 52 39 34 52 44 29 36 40 22 51 49 59 87 60 45 35 37 44 32 30 20 27 24 21 21 32 50 50 60 41 60 36 31 50 27 32 86 56 65 91 78 86 97 110 65 45 47 40 58 71 80 57 86 50 77 60 54 30 55 79 90 58 59 55 47 58 61 57 87 71 63 63 48 35 45 54 55 40 52 49 41 39 27 30 69 87 81 69 64 75 45 54 79 54 49 50 70 105 136 110 55 73 87 59 31 63 79 74 79 57 74 74 59 70 75 66 74 76 87 79 57 55 55 41 28 43 41 30 47 22 25 21 78 54 49 75 71 51 48 60 69 45 50 49 46 50 51 54 65 53 58 85 44 33 20 34 37 43 60 53 48 57 44 30 30 72 120 99 45 40 57 64 53 57 30 55 30 48 20 40 63 76 77 50 64 46 27 60 52 36 45 33 31 37 22 56 46 41 65 56 45 21 25 21 29 59 65 46 62 74 45 35 43 20 39 54 50 46 34 39 34 51 53 62 44 30 36 40 213 70 49 58 56 63 50 67 47 40 45 38 38 62 53 77 85 72 72 71 48 38 82 106 24 46 47 31 54 70 48 45 44 39 64 61 47 36 27 60 232 82 60 80 55 41 52 28 52 113 68 60 55 55 35 66 48 40 40 74 46 50 75 64 62 99 88 86 60 124 172 173 59 48 61 65 68 79 76 75 66 71 80 50 37 36 33 86 23 209 29 76 68 59 61 26 52 222 53 46 55 48 52 69 75 44 31 112 79 101 220 230 231 213 218 231 213 162 175 168 90 48 78 103 80 83 93 85 79 71 77 55 45 46 90 218 39 49 44 30 48 56 31 42 55 201 55 56 47 40 61 35 93 94 70 213 232 223 217 224 224 226 228 227 225 224 225 227 219 61 72 151 121 70 66 92 85 86 86 66 99 101 94 224 34 44 223 40 39 55 23 27 48 232 29 42 45 49 30 32 179 231 210 232 202 211 229 231 229 224 221 225 230 225 209 194 227 222 232 220 156 115 91 45 52 83 89 88 109 111 76 216 53 44 227 46 29 37 52 25 32 229 30 50 42 43 65 230 218 230 209 216 210 227 227 213 223 225 226 228 228 229 228 229 217 206 203 222 216 231 218 103 104 96 85 98 89 80 40 227 90 86 64 213 27 38 32 38 42 75 54 30 104 225 226 202 230 219 222 231 231 231 226 231 226 229 229 225 218 217 223 229 224 231 219 224 231 212 208 216 213 222 75 73 58 48 94 118 100 70 61 223 55 41 36 27 27 39 32 229 223 213 217 231 221 224 231 218 216 222 222 226 226 222 222 226 230 229 221 212 230 208 223 229 219 228 228 225 214 215 202 205 158 106 112 79 64 78 66 208 32 42 39 35 38 31 218 229 208 226 231 217 229 224 226 220 228 231 229 224 223 223 224 225 226 227 227 227 215 226 230 212 229 230 201 228 220 229 225 210 212 215 231 61 50 62 41 216 60 26 40 39 47 26 213 222 232 223 209 229 223 220 221 231 225 208 207 221 228 230 229 218 205 201 211 221 230 216 219 225 226 229 229 224 230 201 230 214 216 214 202 65 55 39 63 215 40 72 21 28 31 27 214 231 208 227 230 225 226 225 207 226 222 221 225 227 225 224 223 225 226 226 225 222 214 225 204 210 219 216 225 216 213 230 221 224 229 202 225 63 62 50 54 223 27 29 36 30 32 29 210 226 211 230 231 197 221 225 228 227 222 220 222 226 224 224 224 223 223 223 222 222 221 222 224 224 221 217 212 209 228 222 213 224 222 221 216 69 60 60 59 219 33 52 40 31 31 71 204 232 231 202 227 229 227 226 226 226 227 228 227 227 224 223 223 223 223 222 222 222 226 225 224 224 224 224 224 224 223 219 210 220 216 213 210 65 55 76 70 218 44 22 24 31 33 38 209 207 210 225 230 219 227 221 216 219 225 227 225 221 223 223 223 222 222 222 221 221 215 216 218 220 222 223 225 225 221 220 213 222 215 212 211 69 100 70 163 60 29 37 29 34 29 22 231 231 227 230 220 230 222 216 211 212 219 224 222 217 222 222 222 222 221 221 220 220 205 209 215 220 222 220 217 214 218 220 216 225 217 214 217 79 85 78 219 32 20 25 44 36 25 51 216 202 221 209 216 217 222 219 215 217 220 222 224 223 222 221 221 220 220 220 220 220 212 215 220 222 222 221 216 214 212 216 215 224 215 215 220 85 98 73 186 25 37 21 35 47 24 21 230 222 224 219 222 229 220 221 221 220 220 221 223 225 221 221 220 220 220 220 220 220 224 223 221 221 219 219 220 219 214 218 216 224 215 215 221 86 71 217 20 20 22 38 39 35 230 24 203 214 229 230 206 220 220 220 220 220 220 220 221 221 220 220 220 219 220 220 218 218 223 221 220 217 216 217 218 220 218 220 216 222 212 209 215 78 87 182 65 25 24 44 23 29 66 21 216 205 213 217 225 220 223 222 221 222 223 223 221 219 221 220 219 220 220 218 218 219 217 218 218 219 220 219 219 218 217 218 211 216 204 199 202 64 211 35 104 106 30 30 37 29 28 222 34 210 218 213 208 220 217 221 225 220 212 229 221 222 223 222 220 218 218 218 218 219 220 224 221 214 218 226 219 200 195 220 214 209 228 201 165 221 23 48 132 127 48 25 30 32 21 26 51 231 203 227 229 218 218 222 215 188 229 218 213 222 216 216 216 217 218 220 221 221 218 205 198 202 207 209 215 223 214 209 215 212 197 217 232 27 23 90 134 110 50 22 30 29 29 30 49 204 220 219 211 224 210 215 207 229 203 214 213 218 218 218 218 217 217 216 214 213 218 211 212 219 218 209 208 216 220 221 202 211 200 212 35 29 28 133 140 91 50 24 32 29 26 21 21 221 212 214 215 222 224 208 226 229 207 199 229 212 221 220 220 218 216 213 210 209 212 218 218 213 209 211 215 216 216 199 226 206 222 34 41 29 40 139 143 80 44 28 28 28 20 32 21 29 25 217 223 208 222 220 209 199 219 217 221 216 215 215 217 218 218 217 215 214 201 209 216 217 214 212 211 211 198 220 209 38 36 34 35 20 68 125 144 78 33 30 21 22 22 20 25 24 23 24 23 205 212 217 215 228 204 223 203 221 217 217 217 217 216 215 214 214 225 208 205 219 216 199 200 218 100 52 56 25 45 34 29 51 107 128 142 78 30 33 21 22 24 40 35 20 29 33 22 36 27 49 183 223 229 204 201 216 219 218 217 214 213 211 210 210 208 199 208 223 193 123 63 42 62 43 31 34 46 37 35 80 132 149 126 64 29 28 24 23 45 32 34 40 38 43 33 30 36 23 36 28 30 56 77 208 213 212 211 211 212 213 214 216 95 83 76 76 73 57 41 33 42 43 36 32 33 46 37 147 132 162 103 40 24 21 22 21        0         angry   31          3      M   middle_eastern  21478-with-mask.jpg_aug3  train                  3  21478-with-mask.jpg\n",
      "1                                                    121 146 183 181 178 166 112 76 125 137 151 157 162 170 175 176 168 172 178 180 180 181 186 190 180 176 174 176 180 180 175 169 166 163 153 141 143 151 146 132 129 112 116 124 138 126 169 175 89 146 194 180 164 145 98 81 129 142 153 158 163 170 176 177 169 171 174 175 175 175 176 178 179 176 172 174 177 176 169 163 160 160 152 143 143 147 138 123 129 119 115 126 132 128 163 166 82 151 190 167 153 132 91 97 131 141 151 154 158 166 171 174 174 172 170 170 171 171 169 168 170 168 166 167 168 167 162 157 155 158 153 146 145 145 134 117 124 123 109 125 120 135 161 161 131 171 178 151 150 123 82 107 133 142 150 152 154 162 169 171 176 171 169 169 172 174 171 168 166 164 164 166 167 167 162 159 155 157 153 147 146 144 133 120 116 121 102 121 110 141 164 167 174 186 177 153 149 108 69 112 134 144 151 153 155 162 168 170 171 168 166 168 172 176 175 174 174 174 172 172 172 170 166 163 155 154 150 144 142 141 134 126 116 123 102 118 105 135 163 168 154 169 177 161 142 100 76 127 127 137 145 147 150 157 161 162 167 166 163 164 168 171 172 174 177 177 176 174 170 166 162 160 159 155 149 143 140 136 132 128 119 123 110 119 106 118 151 159 128 150 171 153 127 103 93 126 121 133 143 145 149 154 158 159 169 169 168 166 163 164 167 170 174 175 176 175 171 168 166 164 168 162 157 151 144 137 132 129 119 117 119 121 111 99 136 145 137 154 170 138 110 107 95 102 127 138 150 154 157 162 166 164 175 175 174 168 162 160 163 167 174 177 179 181 180 180 180 180 176 171 166 160 152 142 134 131 114 110 124 124 118 88 127 136 112 151 145 118 114 100 92 116 136 145 152 155 161 169 170 164 192 186 166 170 170 161 169 163 168 177 186 188 188 185 180 176 163 167 164 166 164 147 138 150 124 112 108 119 128 82 115 127 109 149 147 121 111 93 88 112 125 143 162 171 178 185 187 185 178 174 158 169 175 166 171 161 168 175 180 178 170 160 153 149 154 159 150 147 160 161 149 144 126 125 95 101 124 90 116 106 110 144 145 124 108 88 83 109 129 146 161 162 158 157 158 159 155 157 149 168 177 168 170 158 151 155 155 146 131 117 112 115 129 144 141 133 145 157 151 145 145 140 137 106 97 66 65 107 120 140 138 121 105 85 85 108 138 143 142 132 118 110 109 110 132 142 144 166 172 161 163 154 134 133 127 115 99 91 99 111 117 141 150 143 140 136 141 154 160 106 135 110 125 114 37 92 137 140 133 119 103 86 92 111 129 127 124 118 111 103 100 100 115 132 140 160 161 147 155 151 134 126 117 107 99 101 123 146 141 151 158 160 150 125 124 149 145 127 144 133 119 89 23 45 154 145 137 126 102 85 95 117 117 117 121 128 127 118 110 106 110 126 131 149 149 137 149 147 137 127 118 114 112 119 144 171 166 155 149 158 155 126 112 131 131 169 126 115 48 5 39 32 166 155 153 141 103 80 94 119 117 120 129 136 132 119 111 111 114 120 117 134 140 134 146 144 135 125 120 123 123 124 140 160 161 154 145 149 151 135 125 138 134 100 33 67 47 53 102 90 170 162 167 153 105 74 92 120 123 126 133 135 126 114 114 123 117 117 106 123 135 135 146 141 135 126 125 131 129 123 128 141 145 158 158 150 147 145 152 169 131 22 25 92 88 114 117 159 152 168 174 170 102 60 100 110 120 145 114 120 125 129 174 159 143 142 126 121 127 134 134 144 148 120 133 136 128 78 63 48 48 90 114 116 125 132 128 127 102 97 100 120 123 124 134 141 164 172 177 153 111 39 103 128 101 125 145 164 163 146 136 124 138 142 136 127 130 147 156 156 143 145 147 103 89 70 50 0 11 37 50 60 89 108 105 97 111 126 118 118 127 152 130 127 160 192 161 171 111 50 146 102 126 131 143 118 103 107 98 103 110 113 124 122 137 162 178 164 143 141 143 106 92 78 82 55 53 95 114 98 84 82 92 110 117 124 133 138 136 131 131 119 162 201 158 170 95 81 97 134 125 132 108 51 27 47 67 72 66 76 111 116 124 136 170 172 121 116 136 127 121 106 127 131 131 151 154 146 151 152 145 143 120 141 134 137 118 171 93 124 166 171 172 137 110 133 83 255 117 118 60 30 11 22 90 108 88 71 86 93 128 132 159 160 125 121 139 132 144 145 158 140 145 161 164 166 178 178 163 155 162 137 137 138 142 120 254 88 183 169 157 112 83 90 135 125 109 102 55 75 72 58 135 171 141 149 162 128 137 111 144 174 174 115 102 116 149 141 152 150 149 176 187 180 172 160 151 157 149 158 136 141 131 247 124 247 155 171 136 142 120 124 248 94 89 103 110 143 142 119 138 150 142 144 141 136 247 255 255 243 222 141 124 149 166 123 127 143 152 154 149 152 170 171 154 144 128 137 132 143 131 255 90 248 166 190 150 132 121 102 119 127 116 137 153 130 120 136 131 125 157 247 255 227 255 243 249 255 255 247 255 249 226 167 138 113 119 136 137 126 118 110 111 125 120 138 124 114 115 237 132 92 150 158 151 126 132 75 115 124 247 141 146 171 142 157 159 253 245 248 246 238 239 246 253 252 244 230 226 235 247 248 246 246 187 140 110 89 113 108 127 132 111 142 109 119 111 201 101 100 134 153 144 147 102 235 102 142 254 149 146 142 149 234 243 247 248 253 253 250 250 253 254 253 253 249 250 254 255 251 237 229 242 255 247 187 126 117 127 137 106 125 100 117 132 120 111 91 163 112 115 125 124 255 62 131 239 153 143 156 234 255 243 253 249 252 253 252 253 253 253 250 255 253 252 252 252 250 247 248 246 237 222 254 254 242 161 109 128 132 109 101 238 129 101 84 216 137 111 106 154 227 67 119 252 142 189 238 254 252 249 247 252 252 252 252 253 253 252 249 253 252 250 248 247 250 253 255 254 251 243 251 235 227 228 252 255 106 120 114 249 103 92 110 206 201 138 100 105 245 85 99 241 236 247 226 255 253 239 255 254 252 251 252 252 252 252 252 251 252 254 253 252 251 250 248 251 252 254 244 253 253 253 231 238 246 234 108 231 127 96 94 193 205 188 98 72 255 65 70 255 242 255 251 238 253 255 250 253 251 246 250 251 251 251 252 251 252 252 249 246 249 250 248 246 243 251 237 251 242 252 246 246 248 252 243 255 92 115 88 215 196 222 119 99 248 58 55 247 254 251 252 255 255 233 250 252 245 242 246 251 250 250 251 251 251 243 233 235 246 252 252 253 243 246 253 253 244 242 251 239 255 228 216 248 90 102 104 203 205 202 135 92 251 65 33 254 255 252 253 246 255 243 239 252 248 244 251 253 252 252 252 251 252 251 248 249 252 251 246 217 243 245 250 236 252 251 252 254 236 253 237 233 100 91 106 213 185 204 206 112 238 74 38 255 253 254 246 253 230 244 254 250 251 252 251 249 249 251 251 250 250 250 250 249 248 246 246 248 250 250 247 241 238 243 248 251 252 247 219 238 96 117 92 203 202 202 181 146 248 75 66 236 252 253 224 245 251 253 248 253 254 254 253 252 252 252 252 246 247 250 251 252 252 252 253 251 251 251 250 249 247 245 245 234 241 255 215 255 108 93 105 204 198 203 193 184 231 93 74 252 252 249 241 254 252 251 250 247 249 251 251 249 247 247 247 251 251 251 249 248 244 242 242 251 250 250 251 251 250 246 242 251 248 252 197 237 95 101 98 203 176 186 203 178 185 152 91 239 245 250 252 254 249 243 251 237 241 245 247 247 246 246 248 252 251 251 246 241 235 231 229 248 248 248 247 247 247 243 242 242 244 243 241 249 114 139 82 185 200 190 192 183 184 239 162 171 232 252 239 234 251 250 242 243 246 250 252 252 252 252 251 249 249 249 248 248 246 245 244 244 248 248 246 240 239 242 247 249 246 237 241 236 102 95 109 124 210 204 174 204 200 244 189 161 226 252 251 235 251 249 251 250 252 252 252 252 250 250 249 246 248 248 249 250 250 250 249 246 248 249 246 240 239 244 249 248 240 240 223 252 134 116 235 84 135 187 169 198 185 191 187 194 236 252 255 249 251 244 253 250 250 251 249 247 245 245 246 248 248 248 247 246 245 243 242 246 247 248 247 243 242 245 247 243 247 250 219 239 90 109 107 128 72 182 200 197 189 197 244 189 250 253 246 233 255 251 243 249 249 249 248 247 248 248 250 246 246 247 247 247 246 246 245 245 245 244 246 247 247 244 241 240 250 240 226 237 106 253 60 201 109 100 179 197 183 173 175 170 252 239 239 252 240 247 250 252 251 248 245 248 250 250 249 245 247 249 249 248 246 243 242 240 251 247 242 239 238 244 222 228 233 252 239 97 252 98 58 179 138 144 134 125 105 146 168 254 239 209 226 240 255 237 226 238 245 246 239 240 247 249 243 242 241 242 243 245 245 244 242 235 219 210 234 248 248 248 243 244 209 228 230 255 82 93 69 83 147 156 152 118 163 142 115 144 245 255 250 222 252 228 249 242 251 250 233 222 226 221 210 216 214 218 225 235 242 246 246 250 238 238 238 234 227 220 234 239 250 216 228 104 93 72 67 125 137 139 83 131 148 166 128 93 249 221 252 249 230 254 226 238 243 244 243 243 248 249 248 250 248 245 245 246 245 239 233 206 225 249 245 237 242 234 241 248 220 246 174 84 100 72 45 81 88 84 150 144 148 110 133 152 121 241 251 238 249 230 235 250 242 235 231 225 213 209 211 206 209 216 229 240 246 247 246 248 245 241 231 231 240 239 237 223 225 106 99 68 71 64 68 84 68 96 102 138 116 137 139 128 155 116 140 254 226 243 251 243 241 243 247 247 246 248 250 248 248 248 248 247 242 237 233 241 233 223 247 247 222 227 231 103 134 78 93 82 41 66 37 129 121 107 111 82 110 116 111 124 104 119 120 91 114 245 227 222 244 250 241 231 237 239 232 234 238 239 237 232 231 234 239 232 239 213 246 229 154 142 111 108 65 80 98 56 34 61 95 147 100 109 118 81 53 98 136 125 113 106 113 114 83 61 75 171 223 247 227 218 241 248 238 238 240 239 232 224 223 231 240 246 220 111 112 124 109 144 98 84 83 65 35 66 55 48 67        5           sad   26          2      M            white   9065-with-mask.jpg_aug3  train                  3   9065-with-mask.jpg\n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 77 80 80 77 79 85 84 79 72 83 88 81 78 83 84 79 125 118 83 28 32 59 43 35 45 43 41 38 38 39 41 43 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 77 81 82 76 75 78 80 78 93 74 70 83 85 81 101 133 135 135 128 81 33 33 47 51 43 43 42 42 42 42 42 42 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 76 81 82 78 75 77 79 80 78 88 84 73 89 125 141 132 121 119 133 123 61 30 44 36 39 40 42 44 46 46 45 45 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 76 78 80 80 81 82 82 81 84 74 80 107 130 133 125 121 141 131 125 129 89 39 40 41 43 43 43 43 43 42 41 40 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 79 76 77 81 85 84 80 77 79 82 99 125 139 138 136 139 122 137 138 153 146 76 32 49 48 46 44 42 41 42 43 44 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 82 77 76 80 82 80 79 79 77 116 140 134 136 163 186 190 210 211 201 201 212 137 34 36 35 36 38 42 48 56 64 68 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 81 79 80 81 79 79 88 99 135 139 162 187 181 158 162 186 164 135 139 141 182 177 101 113 111 113 118 124 132 140 147 151 80 80 80 80 80 80 80 80 81 81 81 80 80 79 79 79 79 80 83 83 78 81 101 124 171 189 205 207 194 165 118 77 95 82 149 163 186 199 136 149 146 147 147 147 147 145 143 142 81 81 77 81 85 78 76 88 80 79 79 82 86 86 81 75 86 71 83 92 84 115 169 191 207 193 184 206 197 195 223 198 212 212 219 198 201 198 139 134 144 145 142 138 139 143 142 139 80 85 88 85 80 75 74 75 82 89 89 81 78 82 82 77 68 95 81 74 132 187 196 193 196 195 201 196 191 197 200 205 190 182 195 191 200 201 154 137 142 145 145 144 147 151 149 144 66 72 83 84 77 82 89 83 91 71 64 79 89 84 82 88 88 88 83 120 189 209 195 199 198 186 201 194 203 206 176 194 207 197 202 186 188 196 153 88 134 132 125 112 100 90 77 65 81 72 77 82 74 77 85 83 79 87 95 93 77 64 67 78 100 75 120 192 202 187 193 200 205 183 194 199 199 200 192 205 178 178 181 158 167 192 157 36 24 28 31 33 38 44 43 39 135 109 95 94 84 72 70 76 69 82 76 60 76 115 127 112 77 113 179 208 191 195 208 194 197 196 198 199 174 184 220 200 142 94 92 140 200 205 167 33 51 52 49 45 45 47 45 40 157 143 120 114 117 103 96 111 109 104 112 133 140 118 82 57 95 171 205 195 203 208 198 197 190 205 196 194 178 182 194 131 93 155 175 141 161 197 203 41 41 42 40 38 41 47 48 45 126 150 135 120 139 136 125 143 140 131 133 131 98 68 95 149 153 191 199 194 205 197 187 200 196 202 191 195 198 167 141 140 203 148 96 119 190 180 173 38 43 44 44 41 43 46 44 40 96 151 141 111 132 134 116 129 123 136 129 104 99 119 130 124 183 180 196 196 177 190 208 194 203 199 198 200 198 132 120 254 141 124 54 28 108 153 187 45 37 40 42 41 43 45 42 35 83 118 159 134 117 134 127 131 128 134 119 105 128 142 129 142 204 144 146 187 191 212 198 198 194 206 201 206 191 151 216 248 174 87 34 47 128 157 183 55 32 59 40 36 53 27 59 45 81 105 150 138 118 130 130 131 140 118 116 154 115 127 116 159 128 159 164 171 207 169 213 199 205 203 192 201 207 191 244 246 207 174 118 117 173 198 206 63 23 37 29 57 28 56 21 41 80 87 135 145 120 125 132 129 111 133 128 118 146 143 130 114 198 200 204 184 155 213 182 200 198 199 200 201 198 192 249 245 221 196 198 175 207 253 192 112 36 39 44 26 51 46 40 53 83 75 122 151 125 120 134 128 123 134 111 146 126 111 245 212 205 180 133 112 145 172 209 195 196 194 205 203 189 183 243 252 251 250 218 242 245 231 192 153 25 38 40 46 30 45 32 50 87 72 111 153 132 117 133 126 136 117 132 127 137 255 188 243 143 122 37 30 133 151 171 213 210 190 195 200 200 190 237 255 254 229 248 247 239 251 173 217 82 32 35 61 46 35 37 38 87 75 102 149 139 117 131 126 130 145 142 128 111 215 255 229 202 72 38 71 77 180 185 187 208 193 198 195 198 177 210 249 238 243 223 245 240 240 233 245 254 12 51 32 11 52 63 35 82 79 93 141 143 119 129 128 126 114 121 133 246 235 255 236 199 179 93 79 183 178 206 194 196 200 203 189 205 185 200 242 253 242 253 247 241 254 236 250 240 248 13 52 44 23 33 47 78 81 87 134 146 120 128 129 132 126 136 141 227 236 249 215 218 203 217 207 177 224 221 186 200 202 193 183 239 240 230 247 225 221 224 245 247 242 249 243 216 250 240 182 32 54 26 36 74 90 80 134 149 108 124 129 132 123 127 172 140 251 252 236 207 232 234 209 231 253 217 192 199 226 239 249 234 218 237 249 247 247 247 247 248 248 248 248 239 254 210 243 244 52 28 39 75 86 76 132 148 110 127 127 123 136 147 239 180 255 252 240 239 253 254 238 251 253 238 232 232 239 235 247 247 237 245 242 248 247 247 246 246 245 245 244 250 238 252 229 227 254 22 43 77 82 71 130 147 113 130 125 127 135 117 236 147 221 243 255 240 243 247 235 238 241 229 242 249 246 232 244 250 244 248 240 244 245 246 246 247 248 249 250 248 245 245 242 253 236 245 82 81 79 69 130 145 114 135 125 133 136 116 242 126 143 176 199 238 236 243 233 232 239 233 246 242 247 239 247 244 235 247 247 245 244 244 244 243 243 242 242 245 244 247 241 249 243 252 234 84 79 73 133 141 111 137 126 134 134 131 251 136 118 165 176 238 236 246 237 237 251 246 246 239 247 243 249 245 233 244 245 248 247 244 240 236 231 228 227 242 253 221 253 246 251 232 253 84 80 78 137 133 102 136 126 136 125 125 232 131 138 207 220 232 224 239 237 235 250 244 236 244 244 233 243 246 235 237 228 245 244 243 242 241 239 238 238 248 225 253 230 243 251 249 228 82 80 84 139 124 91 132 125 133 129 135 242 131 162 202 197 239 219 239 248 241 244 239 240 243 240 228 239 244 235 237 227 240 241 243 245 247 249 250 251 226 253 247 218 244 253 233 247 80 79 87 140 118 83 128 123 128 130 130 242 120 185 206 196 240 209 232 249 239 228 226 238 239 243 236 245 245 236 246 245 243 243 243 243 243 243 243 243 252 238 241 252 237 235 253 237 90 66 86 158 96 64 111 143 120 152 124 157 121 186 192 206 225 230 237 220 235 248 229 245 242 243 243 243 243 241 241 240 245 244 243 243 241 241 240 239 249 251 241 242 245 251 214 250 84 75 94 144 81 80 106 123 137 125 117 164 237 171 208 193 239 236 243 232 239 247 231 240 245 240 235 233 234 238 243 246 240 238 235 231 226 222 218 217 237 240 251 228 252 251 233 240 82 79 108 133 72 77 91 122 137 130 128 126 216 177 218 198 236 223 234 236 236 243 238 239 242 236 230 228 232 239 243 244 247 245 245 243 242 240 239 239 238 237 249 228 248 239 236 242 83 74 125 128 84 59 74 126 117 134 145 130 140 230 199 185 232 214 225 236 230 236 243 238 237 234 232 235 239 242 240 237 238 238 240 242 244 246 247 248 245 243 235 247 227 238 233 249 80 78 140 117 110 63 68 95 144 126 128 142 117 227 207 198 238 226 231 240 230 232 244 236 239 237 237 239 242 242 240 237 237 237 236 236 236 236 236 236 241 243 237 249 234 253 237 200 73 98 142 107 131 95 80 54 129 127 128 124 122 147 232 212 219 228 230 236 232 232 247 238 241 240 238 236 236 238 241 243 243 243 243 242 242 242 242 241 238 243 251 233 248 254 228 103 74 121 131 115 135 118 99 71 72 131 144 129 137 111 201 200 188 224 225 229 233 231 242 234 232 235 238 237 235 235 239 242 234 235 236 238 239 241 242 243 243 242 249 235 239 243 216 82 80 134 117 132 129 119 113 122 98 142 120 129 127 130 153 231 179 231 231 229 235 228 233 223 217 227 239 243 239 235 234 236 238 238 239 239 240 240 240 240 249 239 230 252 222 235 222 142 117 104 109 132 139 123 116 124 133 133 126 127 133 130 134 150 205 223 219 234 226 235 221 231 234 240 226 229 238 241 243 224 211 211 226 239 238 240 240 232 213 224 251 237 224 239 234 236 131 100 88 110 132 130 123 123 124 131 130 129 132 126 125 136 182 226 234 232 219 238 230 231 232 236 223 226 230 228 235 224 239 230 234 240 238 242 243 237 229 251 233 202 251 238 234 139 120 87 69 88 116 128 132 136 124 127 119 117 130 135 129 129 138 190 216 224 220 235 232 236 231 234 225 235 239 235 246 245 229 219 218 221 221 228 233 225 223 247 233 226 246 200 235 108 91 77 70 80 91 99 112 128 122 110 88 87 117 139 136 129 116 140 169 204 221 220 216 230 240 237 225 236 236 223 229 227 233 229 234 237 234 240 242 233 231 223 244 234 240 241 117 125 80 78 79 80 75 71 77 87 97 89 69 68 94 116 123 128 129 126 136 166 202 204 203 213 223 219 211 231 241 232 235 228 232 233 241 240 232 235 238 229 246 237 218 249 146 137 121 138 82 81 82 84 83 79 73 70 74 81 80 78 82 86 102 127 136 131 126 127 169 190 204 206 197 198 194 217 233 232 235 223 224 226 232 230 224 233 238 227 219 234 106 133 139 109 140 118 79 80 81 83 87 89 85 80 75 83 87 89 84 74 88 122 121 122 125 115 144 153 181 198 195 201 191 197 200 194 193 176 230 229 233 234 233 240 234 213 135 106 141 121 117 140 120 117 73 80 83 77 73 75 82 85 87 80 75 83 85 74 82 113 110 109 127 126 135 107 137 179 191 205 198 200 201 201 207 192 201 197 199 199 196 193 169 132 111 128 111 127 130 119 136 134        2          fear   28          2      M            white  10938-with-mask.jpg_aug1  train                  1  10938-with-mask.jpg\n",
      "3                                                                                                                                                 255 245 255 250 250 248 255 242 101 42 57 78 70 69 64 74 64 68 68 63 59 57 52 47 54 70 81 81 79 82 87 88 90 90 92 89 74 57 51 54 48 71 208 255 255 255 255 251 255 248 255 251 251 251 255 196 70 50 75 86 81 82 72 76 82 87 89 86 84 84 81 77 89 100 109 109 108 110 112 111 106 104 107 109 101 82 64 56 49 53 158 242 255 250 253 255 255 253 253 252 252 254 238 130 47 69 93 88 87 91 79 83 88 94 98 97 96 96 95 92 94 100 106 109 111 114 112 108 111 108 111 119 118 99 70 49 54 40 98 225 255 247 250 255 254 255 251 254 250 255 217 77 52 89 97 81 88 87 78 90 89 97 102 100 98 98 97 95 105 108 113 120 127 129 124 118 107 104 107 115 117 101 71 47 60 44 61 207 255 248 251 255 252 255 252 254 248 253 191 50 64 96 88 79 92 82 75 93 94 104 112 111 110 110 110 109 104 104 108 119 127 126 116 108 107 106 108 112 113 102 79 59 55 53 48 184 255 252 255 253 252 255 255 253 249 252 159 42 69 95 82 84 99 83 78 91 93 105 115 117 117 119 121 121 127 125 131 142 147 140 125 115 109 109 110 111 111 104 86 69 49 54 45 155 248 255 255 252 254 253 255 251 254 254 127 40 78 102 85 86 96 85 90 90 94 107 119 121 121 123 125 126 123 123 131 144 147 135 117 107 110 111 111 112 115 109 87 66 55 51 46 131 245 255 253 254 255 248 254 249 255 255 107 39 89 114 92 83 85 84 100 92 107 120 131 132 130 130 132 132 136 137 148 163 166 152 134 125 114 114 114 117 123 116 89 61 67 51 47 119 246 254 248 255 255 253 255 244 255 250 100 42 87 110 83 73 90 86 89 101 104 113 128 139 139 136 138 145 140 152 166 172 167 155 141 130 118 119 117 116 119 115 91 65 68 64 39 121 255 247 253 255 255 254 255 245 255 247 102 43 95 123 103 92 103 99 107 119 131 135 143 148 147 144 150 159 155 159 165 171 174 172 166 161 153 138 124 122 123 118 106 97 87 72 31 81 226 255 254 255 253 252 255 249 255 253 120 60 114 136 109 89 91 90 104 116 132 137 147 155 157 157 164 173 179 166 148 135 126 117 106 98 120 117 123 132 128 116 116 125 82 82 51 95 238 255 254 245 253 252 255 251 255 252 134 73 138 136 93 67 69 74 91 96 110 120 139 157 166 169 173 180 180 161 140 129 126 121 113 108 103 103 109 120 126 125 123 123 80 82 37 99 227 255 251 255 255 255 255 252 250 245 144 82 151 128 81 71 86 97 111 106 114 124 142 162 173 176 179 184 183 171 163 169 179 183 184 185 174 155 126 109 121 139 133 113 83 75 25 130 245 247 255 255 254 254 253 255 253 255 173 112 156 124 90 106 131 138 147 138 141 145 156 168 176 178 183 188 197 189 186 193 196 193 193 198 202 204 183 145 128 135 136 125 93 69 37 155 252 255 255 246 253 253 251 255 255 255 196 137 166 130 106 131 142 132 140 138 139 143 153 167 175 179 183 188 198 190 187 185 175 162 160 169 157 185 200 180 150 137 138 139 111 64 52 110 170 242 253 255 255 255 251 255 246 252 191 130 178 138 113 130 121 93 102 110 109 118 138 160 174 179 181 184 202 192 181 165 139 113 108 117 131 144 161 171 169 157 144 135 101 65 99 105 127 240 244 255 254 251 254 255 255 245 194 129 175 145 108 111 83 83 80 97 96 103 112 130 155 169 173 188 183 176 186 135 99 94 68 89 110 103 153 167 164 152 151 135 113 80 147 152 111 223 255 244 255 253 251 250 252 254 223 174 172 127 113 82 97 136 53 63 119 119 87 134 150 165 181 195 212 183 150 115 143 138 58 45 169 142 108 139 161 154 148 141 118 126 158 155 117 198 255 254 251 253 255 255 254 255 229 186 136 105 111 79 123 173 66 64 178 156 79 125 123 139 170 188 193 183 148 131 191 179 79 63 176 161 136 167 176 159 127 152 131 150 137 136 129 199 255 253 249 255 255 255 252 253 232 194 150 110 97 87 106 124 82 74 146 124 83 111 111 125 151 163 163 177 157 122 133 120 85 118 153 127 146 140 139 154 162 219 135 142 135 140 146 220 255 248 255 255 255 248 246 255 251 222 223 111 90 101 97 104 110 109 103 85 116 104 112 123 134 139 146 166 175 149 125 115 126 165 192 157 171 153 158 171 241 228 163 146 168 157 143 228 254 253 252 254 255 253 253 255 246 211 255 95 102 122 119 129 116 110 108 119 230 235 253 252 231 210 162 159 157 150 139 132 136 145 165 173 174 180 178 141 240 139 230 169 155 123 121 228 252 255 249 252 255 255 255 255 226 179 230 109 118 136 131 125 133 125 253 227 253 245 239 239 247 240 248 240 198 174 173 156 148 162 162 185 188 184 179 154 232 154 229 174 110 88 133 237 254 254 255 253 252 249 251 254 227 180 167 140 124 148 149 139 238 248 240 215 230 253 246 243 252 237 203 252 243 232 237 187 153 181 200 195 216 180 176 183 175 145 153 159 98 107 178 247 252 252 251 255 255 244 255 255 221 197 144 133 125 144 142 248 247 207 247 247 248 246 244 243 244 245 243 249 239 223 232 248 228 189 213 200 196 199 185 160 157 143 138 204 127 164 220 255 255 251 250 254 255 248 255 255 232 224 166 106 142 183 233 240 250 239 238 242 247 249 249 246 245 245 251 245 239 244 248 243 231 222 215 207 199 194 178 162 160 152 138 219 164 197 236 255 255 254 252 253 255 251 254 255 239 249 175 158 219 226 253 236 251 248 243 245 248 248 248 247 248 248 249 241 241 250 250 240 238 244 234 234 225 212 189 177 159 148 139 236 210 236 252 255 251 255 255 252 255 252 253 248 236 254 195 232 253 251 234 250 241 241 251 248 243 237 235 238 244 249 241 245 246 243 242 246 247 246 243 251 246 237 217 205 157 137 143 243 240 255 255 252 248 255 255 250 255 252 255 250 235 253 227 236 237 253 235 253 234 246 244 241 235 230 228 231 237 243 245 244 242 242 243 246 247 246 235 244 242 243 234 230 157 134 153 243 251 255 255 249 249 255 255 250 255 253 255 255 240 254 228 217 239 248 242 247 244 248 235 237 240 240 240 239 240 241 250 234 230 244 247 235 235 247 242 244 236 242 238 238 148 133 165 241 255 252 254 252 254 255 251 252 255 251 255 255 242 254 227 218 253 246 235 238 251 243 238 242 247 248 248 246 245 244 246 235 233 242 242 233 234 243 248 247 238 248 241 237 136 132 171 237 255 250 255 254 254 254 249 255 255 249 249 251 240 252 254 213 235 253 240 247 250 242 244 245 245 244 241 240 241 243 238 249 250 239 237 246 248 241 233 235 233 251 244 237 131 135 172 234 255 251 255 254 254 252 254 250 251 255 255 241 239 249 248 220 215 235 245 248 249 248 246 246 246 245 244 243 242 241 243 242 242 242 242 242 242 241 244 225 245 214 242 236 134 141 185 222 250 243 255 250 247 255 255 251 252 255 255 249 246 250 253 232 232 248 248 243 240 237 244 235 222 213 212 220 231 239 243 243 243 241 239 238 238 239 238 241 252 230 231 226 137 129 204 244 255 254 250 247 255 251 254 253 253 255 255 254 248 242 248 233 235 247 243 236 238 239 247 244 240 237 236 238 241 243 243 244 243 240 235 233 236 238 237 240 236 233 240 247 151 134 231 255 255 255 242 247 255 247 253 254 254 250 252 254 245 232 253 235 233 240 235 235 243 246 238 242 247 251 251 247 240 235 241 243 243 239 234 233 236 240 244 237 224 226 237 236 116 148 243 255 233 255 253 253 255 251 252 254 254 249 251 255 248 233 253 244 240 244 240 240 244 242 242 241 239 238 238 238 239 240 240 241 241 239 236 236 239 242 236 235 240 235 243 228 111 216 216 255 243 253 255 255 249 255 251 254 254 251 254 255 254 246 245 234 238 247 246 245 245 238 247 245 243 240 240 242 244 246 239 239 239 239 239 239 239 239 238 231 238 232 245 235 137 221 158 236 255 253 251 255 248 254 252 253 254 254 255 255 254 253 226 223 233 243 240 241 244 240 236 238 240 242 242 240 238 236 240 237 236 238 240 240 236 231 245 234 227 217 219 223 165 133 101 143 241 255 247 255 253 253 253 253 252 254 252 250 252 253 233 232 240 242 232 231 241 243 242 241 241 241 241 241 242 243 241 237 234 237 241 240 232 224 221 235 237 234 215 239 243 127 68 46 191 255 253 253 254 254 253 253 253 254 254 254 254 253 253 230 232 230 245 235 250 232 236 215 226 227 236 243 225 234 215 223 228 237 245 239 229 233 230 224 218 234 244 227 132 128 80 13 115 244 251 250 255 248 253 253 253 254 254 254 254 254 239 245 233 250 234 232 222 233 245 228 236 235 238 242 228 238 229 238 238 233 228 220 223 242 229 223 242 225 223 116 133 117 73 14 74 185 238 254 254 255 253 253 253 254 254 254 254 254 254 237 221 214 249 245 245 244 231 220 230 234 236 234 221 228 217 225 228 232 238 231 227 236 234 245 213 232 104 119 128 108 64 25 52 146 242 255 247 255 253 253 253 253 254 254 254 254 254 254 253 241 217 214 230 237 249 235 229 230 231 230 229 236 230 233 230 231 237 231 226 234 221 210 184 83 138 122 105 117 41 15 37 116 214 255 246 255 253 253 253 253 254 254 254 254 244 254 254 233 129 242 238 221 238 234 234 248 251 242 233 226 236 238 231 227 228 221 217 226 178 106 85 106 104 133 100 98 35 7 39 101 167 227 252 254 253 253 253 253 254 254 254 254 255 242 239 233 57 37 43 132 237 230 215 225 230 224 235 236 216 213 213 229 241 207 143 101 91 84 80 125 129 115 114 74 30 7 54 108 141 186 208 208 253 253 253 253 254 254 254 254 242 252 254 164 82 58 20 7 47 90 139 208 239 232 237 228 253 210 143 114 123 119 97 84 81 85 129 147 113 110 136 39 16 4 50 100 130 145 129 116 253 253 253 253 254 254 254 254 254 238 191 121 77 59 1 39 43 66 75 103 104 90 112 117 119 123 120 116 114 99 88 93 106 111 131 120 114 118 66 51 29 21 48 93 140 145 109 99        6      surprise   25          2      M  latino_hispanic  20886-with-mask.jpg_aug0  train                  0  20886-with-mask.jpg\n",
      "4  138 189 207 187 164 140 131 145 158 178 185 182 185 191 202 218 223 231 232 225 225 233 233 226 238 234 229 229 230 229 224 218 211 203 199 201 201 197 197 201 221 246 162 89 82 113 103 119 134 187 202 174 150 132 129 143 154 172 178 176 181 188 197 212 216 224 226 220 219 224 222 213 229 226 223 225 229 229 226 222 216 208 203 204 203 199 198 201 202 230 203 119 90 97 101 112 145 195 201 161 138 130 131 143 163 178 182 181 190 198 205 216 220 228 231 227 227 230 227 220 220 217 216 218 222 223 220 217 214 207 201 200 199 196 196 198 197 212 237 149 94 85 101 101 163 204 194 148 131 135 135 140 167 180 183 184 196 205 209 218 222 228 231 230 232 236 236 232 234 232 230 230 231 230 227 224 223 218 212 210 209 209 210 211 207 200 240 170 90 85 101 95 174 200 178 133 130 143 141 139 161 173 176 178 192 200 204 211 218 221 222 221 223 227 228 227 232 231 229 227 226 224 220 218 217 214 209 205 206 210 212 212 205 197 231 199 95 86 95 97 183 196 168 131 140 157 153 149 164 178 182 184 197 205 209 217 224 225 225 225 224 225 224 224 220 220 219 219 217 216 214 213 210 209 204 199 201 207 210 209 190 200 225 230 126 86 89 104 191 197 167 137 148 161 157 156 171 187 192 194 205 213 217 226 230 231 234 237 236 232 229 227 229 230 230 230 229 227 227 227 225 224 218 212 213 221 224 222 189 203 213 240 177 94 95 105 193 197 167 139 147 154 149 152 166 183 189 191 201 208 214 224 222 225 232 238 239 233 227 224 226 227 228 226 224 222 221 221 222 222 215 207 208 216 219 216 203 205 197 232 216 105 106 103 196 187 160 140 145 152 149 149 168 179 178 186 210 212 209 223 231 229 229 232 233 232 231 232 231 223 221 227 227 220 221 227 221 219 219 218 214 214 223 234 215 197 206 231 231 113 79 114 200 191 164 145 154 162 156 152 170 191 195 193 204 207 214 235 234 229 227 231 234 234 232 233 233 235 239 237 228 220 222 229 234 229 229 235 238 236 232 230 228 214 213 243 247 152 95 110 194 187 160 142 152 161 155 149 172 190 193 188 197 205 211 221 233 225 219 221 222 221 221 223 228 233 234 227 219 215 212 209 211 209 213 222 228 226 222 221 226 220 209 244 251 191 106 96 191 190 167 144 148 158 157 156 194 193 184 183 201 216 209 193 221 217 218 221 218 212 213 220 227 226 220 212 213 217 207 192 208 210 215 219 218 216 221 230 219 224 207 243 250 223 118 93 197 204 185 156 150 159 166 173 195 174 153 148 162 177 169 146 179 190 211 229 228 216 214 222 225 228 224 214 211 214 209 200 218 216 217 222 224 224 226 230 219 231 217 249 251 243 132 109 193 208 193 158 146 153 163 173 171 144 124 112 105 112 117 108 117 138 176 212 220 208 205 212 206 218 222 211 194 187 190 194 196 189 190 207 228 236 233 228 217 228 223 247 245 235 125 112 193 211 197 163 150 154 160 165 166 140 131 129 113 108 116 113 97 108 139 176 192 190 192 203 193 198 201 196 180 163 158 161 160 158 166 187 209 224 233 238 222 225 231 246 242 217 109 104 206 224 211 179 167 170 170 170 160 133 136 151 141 129 127 118 124 118 128 156 176 183 194 210 201 189 184 188 184 164 143 133 126 135 148 157 162 175 202 228 239 235 246 255 253 215 106 105 180 213 180 178 179 167 170 161 151 138 138 154 156 138 120 115 113 117 116 124 147 164 178 197 200 183 170 179 170 159 161 139 157 146 137 145 167 192 209 215 240 223 245 255 221 191 105 96 194 170 188 166 177 156 185 179 159 138 121 116 107 91 86 93 98 104 100 103 131 164 181 186 214 217 183 166 160 141 139 140 149 151 150 146 147 165 195 220 227 238 246 248 219 134 86 100 171 166 205 155 176 196 188 169 160 145 135 131 123 111 111 122 85 92 88 91 129 184 211 209 224 226 155 109 115 105 103 118 125 147 168 171 165 174 202 228 227 255 252 247 230 101 81 104 158 190 164 129 151 197 202 201 186 183 185 189 179 154 137 133 105 104 102 106 135 184 214 213 232 213 131 84 96 103 105 102 89 114 144 159 164 175 198 219 224 238 241 239 215 99 80 84 139 132 160 145 161 152 202 217 193 187 187 190 181 158 136 126 103 99 114 134 152 185 215 220 219 186 125 92 88 107 125 105 108 126 146 153 156 171 201 228 234 224 246 240 182 112 91 81 98 161 138 247 120 156 197 178 196 181 166 158 152 143 136 135 119 116 142 168 174 196 225 230 231 200 155 124 101 119 160 155 157 178 197 198 188 192 216 240 240 223 253 239 158 102 101 91 158 140 231 137 126 179 175 191 223 212 198 184 169 156 150 149 177 167 177 177 165 190 223 220 214 208 172 149 133 124 141 148 164 180 199 208 208 209 218 227 226 221 238 226 173 78 99 88 139 247 107 141 175 145 205 184 211 219 230 233 223 206 193 189 183 169 166 150 142 192 243 240 233 254 240 240 245 198 157 150 159 157 160 177 202 220 227 227 233 240 238 238 230 89 119 99 135 236 119 141 230 162 192 207 213 233 246 238 225 218 211 203 213 197 203 234 251 243 241 250 241 240 242 246 245 241 242 246 197 198 215 214 231 225 233 229 228 240 225 213 217 104 137 118 175 166 128 129 238 182 172 197 204 223 236 232 226 226 227 223 240 247 238 217 220 244 252 241 253 251 249 247 241 233 230 232 247 236 234 215 223 216 229 229 213 239 188 148 175 141 131 108 225 129 133 131 245 173 169 194 201 217 228 227 227 235 241 242 219 233 244 244 246 251 250 244 240 239 242 245 245 243 245 250 244 242 251 242 248 231 232 223 227 248 173 133 167 213 140 129 246 154 122 141 244 144 186 202 212 223 231 231 232 239 245 246 243 239 241 248 247 240 242 252 250 248 248 250 247 243 244 249 247 240 245 233 244 237 248 247 231 224 170 159 157 243 119 129 240 172 109 141 241 163 203 218 227 233 238 239 239 242 243 243 246 251 249 242 241 249 251 246 249 248 248 248 247 243 245 250 249 244 248 237 246 235 242 238 234 211 198 187 126 240 99 109 237 148 114 137 241 229 221 237 236 238 241 243 244 244 243 242 240 237 241 249 249 243 241 246 242 240 241 244 244 242 246 251 241 243 253 252 253 239 234 221 248 237 243 191 98 243 109 105 240 116 120 134 226 253 244 242 242 240 240 242 244 245 244 243 251 243 237 242 232 216 224 249 252 251 248 244 238 231 231 235 251 245 247 234 244 238 249 249 243 248 249 158 84 240 113 111 240 100 114 130 200 226 252 233 247 242 239 240 242 243 243 243 202 236 252 248 241 249 248 236 244 242 241 242 241 240 243 248 237 236 248 242 253 245 251 245 239 248 237 136 96 243 116 130 235 106 105 124 161 237 248 239 242 241 239 235 233 236 244 250 239 241 243 242 241 241 243 244 243 243 244 244 244 245 245 245 246 244 241 239 239 242 245 248 244 236 233 130 76 236 124 123 237 82 109 133 150 244 218 250 233 236 240 242 241 240 239 239 247 245 245 245 245 245 244 243 243 243 243 244 244 244 245 245 250 250 250 246 242 239 239 240 243 246 207 73 95 238 124 120 91 92 101 113 157 234 218 234 235 237 240 243 246 245 241 237 243 240 238 239 242 243 241 238 242 242 243 243 243 244 244 244 235 241 247 248 245 242 243 245 224 245 104 106 88 99 121 104 63 244 109 115 166 238 248 245 242 238 234 235 239 242 242 241 235 231 229 232 239 242 240 237 241 242 242 242 243 243 243 243 224 233 242 244 242 240 245 250 238 236 123 84 103 95 109 104 69 241 119 105 134 235 223 230 240 235 229 227 231 236 239 240 239 235 233 237 243 245 244 241 241 241 241 241 242 242 242 243 236 242 245 243 236 233 237 243 247 235 97 95 233 103 82 102 62 112 220 100 121 237 246 237 237 236 235 236 238 240 240 239 243 241 239 240 242 243 241 239 240 240 240 241 241 241 242 242 245 246 248 243 237 235 238 243 218 250 90 73 97 87 88 101 81 60 215 125 89 210 249 234 235 237 240 241 241 240 240 241 240 239 239 238 238 237 237 236 239 239 240 240 240 241 241 241 241 242 243 242 241 241 244 247 217 237 105 237 119 89 139 122 75 74 75 237 111 236 220 216 231 233 234 233 231 231 236 240 236 237 239 239 238 238 239 241 239 239 239 240 240 240 241 241 241 241 241 241 241 241 241 240 239 107 95 131 97 125 96 126 69 79 90 66 242 229 207 245 232 241 220 215 229 239 246 238 236 238 241 242 238 235 239 245 240 239 239 240 241 241 240 239 243 239 248 239 217 230 242 248 240 91 253 81 104 117 110 98 71 94 63 83 119 224 239 221 225 231 223 237 242 223 226 234 216 226 236 241 240 238 236 234 240 239 238 239 241 240 238 235 218 226 232 238 249 244 222 223 239 250 66 108 121 91 92 103 86 65 95 67 106 116 245 226 226 238 231 238 233 212 222 239 229 234 234 227 227 234 238 236 241 239 237 237 238 236 232 227 231 251 241 209 226 234 233 243 235 86 110 112 78 94 116 95 78 71 82 85 111 89 165 217 209 241 238 231 226 222 234 236 238 239 232 220 220 233 240 237 242 239 237 236 236 233 228 224 231 232 235 245 253 228 232 243 99 92 89 90 110 82 103 106 67 83 66 79 99 140 114 147 170 209 220 230 237 233 236 227 225 230 231 229 233 240 238 230 239 238 237 237 236 235 234 233 238 242 238 214 232 246 220 90 93 94 90 90 85 104 86 98 79 61 95 65 108 131 129 106 148 164 171 203 223 216 225 235 237 233 230 231 236 238 235 231 233 236 237 236 233 234 238 243 248 211 238 246 175 77 110 98 103 90 97 86 101 79 100 98 80 67 79 91 94 121 132 122 136 142 137 162 185 188 209 227 238 223 216 223 231 231 232 236 230 234 235 229 221 220 229 238 222 176 187 213 186 83 99 78 83 82 92 105 88 92 94 109 69 86 54 70 99 126 138 119 114 139 136 143 163 178 195 194 198 187 195 221 237 232 228 232 229 234 234 223 208 204 213 224 214 201 198 197 182 85 104 94 88 98 96 77 100 98 93 97        3         happy   27          2      M            white  26359-with-mask.jpg_aug1  train                  1  26359-with-mask.jpg\n",
      "\n",
      "Rows (raw CSV): 21,000\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"\\nCSV dtypes:\"); print(df_raw.dtypes.to_string())\n",
    "print(\"\\nFirst 5 rows:\"); print(df_raw.head(5).to_string())\n",
    "print(f\"\\nRows (raw CSV): {len(df_raw):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c846354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cols = ['pixels', 'emotion_label', 'gender', 'age', 'ethnicity']\n",
    "missing = [c for c in required_cols if c not in df_raw.columns]\n",
    "if missing: raise ValueError(f\"Missing required columns: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1c98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "if EMO_MODE == \"7\":\n",
    "    df['emotion_used'] = df['emotion_label'].apply(map_to_7_emotions)\n",
    "    EMOS = EMO7\n",
    "else:\n",
    "    df['emotion_used'] = df['emotion_label'].apply(map_to_5_emotions)\n",
    "    EMOS = EMO5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "983ea829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped rows due to neutral/unknown mapping policy: 0\n"
     ]
    }
   ],
   "source": [
    "dropped = df['emotion_used'].isna().sum()\n",
    "print(f\"\\nDropped rows due to neutral/unknown mapping policy: {dropped}\")\n",
    "df = df.dropna(subset=['emotion_used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fabbe47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pixels'] = df['pixels'].apply(parse_pixels)\n",
    "bad_pix = df['pixels'].isna().sum()\n",
    "if bad_pix: print(f\" Dropping {bad_pix} rows with malformed pixel strings (not {PIXELS_EXPECTED}).\")\n",
    "df = df.dropna(subset=['pixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d780727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].apply(normalize_gender)\n",
    "df['ethnicity_norm'] = df['ethnicity'].apply(normalize_ethnicity)\n",
    "valid_eth = {'asian','black','latino_hispanic','middle_eastern','white'}\n",
    "df = df[df['ethnicity_norm'].isin(valid_eth)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8901f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "df = df.dropna(subset=['age']); df['age'] = df['age'].astype(int)\n",
    "age_bins = [0, 25, 40, 200]\n",
    "df['age_range3'] = pd.cut(df['age'], bins=age_bins, labels=[0,1,2], right=False)\n",
    "df = df.dropna(subset=['age_range3']); df['age_range3'] = df['age_range3'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e1772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with unknown gender (USE_GENDER=True).\n"
     ]
    }
   ],
   "source": [
    "if USE_GENDER:\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=['gender'])\n",
    "    print(f\"Dropped {before - len(df)} rows with unknown gender (USE_GENDER=True).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5be9a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_emotion_counts = df_raw['emotion_label'].value_counts(dropna=False)\n",
    "bar_chart(raw_emotion_counts, \"Emotion Count (CSV raw)\", \"csv_raw_emotion_count.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70497b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning:\n",
      "\n",
      "Emotion_used distribution:\n",
      "emotion_used\n",
      "angry       3000\n",
      "sad         3000\n",
      "fear        3000\n",
      "surprise    3000\n",
      "happy       3000\n",
      "neutral     3000\n",
      "disgust     3000\n",
      "\n",
      "Gender (0/1) distribution:\n",
      "gender\n",
      "0    16892\n",
      "1     4108\n",
      "\n",
      "Ethnicity (5) distribution:\n",
      "ethnicity_norm\n",
      "white              15856\n",
      "middle_eastern      3066\n",
      "asian               1323\n",
      "latino_hispanic      523\n",
      "black                232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ethnicity_norm\n",
       "white              15856\n",
       "middle_eastern      3066\n",
       "asian               1323\n",
       "latino_hispanic      523\n",
       "black                232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nAfter cleaning:\")\n",
    "report_counts(\"Emotion_used\", df['emotion_used'])\n",
    "report_counts(\"Gender (0/1)\", df['gender'])\n",
    "report_counts(\"Ethnicity (5)\", df['ethnicity_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d85e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_to_idx = {e:i for i,e in enumerate(EMOS)}\n",
    "df['emotion_idx'] = df['emotion_used'].map(emo_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d85e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "eth_le = LabelEncoder()\n",
    "df['ethnicity_label'] = eth_le.fit_transform(df['ethnicity_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "177f1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_counts = df['emotion_used'].value_counts().reindex(EMOS, fill_value=0)\n",
    "bar_chart(emo_counts, f\"Emotion Count (Processed, {len(EMOS)} classes)\", \"processed_emotion_count.png\")\n",
    "gender_counts = df['gender'].value_counts()\n",
    "bar_chart(gender_counts, \"Gender Count (Processed)\", \"processed_gender_count.png\", rotate_xticks=False)\n",
    "age_counts = df['age_range3'].value_counts().sort_index(); age_counts.index = [\"0-24\",\"25-39\",\"40+\"]\n",
    "bar_chart(age_counts, \"Ethnicity Count (Processed)\", \"processed_ethnicity_count.png\")\n",
    "eth_counts = df['ethnicity_label'].value_counts().sort_index(); eth_counts.index = eth_le.inverse_transform(eth_counts.index)\n",
    "bar_chart(eth_counts, \"Ethnicity Count (Processed)\", \"processed_ethnicity_count.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "924cdb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Group-by-pixel split (hashing pixel bytes)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Group-by-pixel split (hashing pixel bytes)\")\n",
    "df['pix_hash'] = df['pixels'].apply(lambda a: hashlib.md5(a.tobytes()).hexdigest())\n",
    "g = (df.groupby('pix_hash')['emotion_idx']\n",
    "       .agg(lambda xs: pd.Series(xs).value_counts().idxmax())\n",
    "       .reset_index(name='majority'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95f28f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train, g_tmp = train_test_split(\n",
    "    g, test_size=0.40, random_state=SEED, stratify=g['majority']\n",
    ")\n",
    "g_val, g_test = train_test_split(\n",
    "    g_tmp, test_size=0.50, random_state=SEED, stratify=g_tmp['majority']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a22e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train, H_val, H_test = set(g_train['pix_hash']), set(g_val['pix_hash']), set(g_test['pix_hash'])\n",
    "assert not (H_train & H_val or H_train & H_test or H_val & H_test), \"Hash leakage across splits!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb88b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes (grouped, no leakage): 12635 4198 4167\n"
     ]
    }
   ],
   "source": [
    "m_tr  = df['pix_hash'].isin(H_train).to_numpy()\n",
    "m_val = df['pix_hash'].isin(H_val).to_numpy()\n",
    "m_te  = df['pix_hash'].isin(H_test).to_numpy()\n",
    "print(\"Sizes (grouped, no leakage):\", m_tr.sum(), m_val.sum(), m_te.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5acd7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all  = np.stack(df['pixels'].values).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_CH).astype('float32') / 255.0\n",
    "yE_int_all = df['emotion_idx'].astype(int).to_numpy()\n",
    "yE_all = to_categorical(yE_int_all, num_classes=len(EMOS))\n",
    "yA_all = to_categorical(df['age_range3'])\n",
    "yT_all = to_categorical(df['ethnicity_label'])\n",
    "if USE_GENDER: yG_all = df['gender'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2da6be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, X_te = X_all[m_tr], X_all[m_val], X_all[m_te]\n",
    "yE_tr, yE_val, yE_te = yE_all[m_tr], yE_all[m_val], yE_all[m_te]\n",
    "yE_tr_int, yE_val_int, yE_te_int = yE_int_all[m_tr], yE_int_all[m_val], yE_int_all[m_te]\n",
    "yA_tr, yA_val, yA_te = yA_all[m_tr], yA_all[m_val], yA_all[m_te]\n",
    "yT_tr, yT_val, yT_te = yT_all[m_tr], yT_all[m_val], yT_all[m_te]\n",
    "if USE_GENDER: yG_tr, yG_val, yG_te = yG_all[m_tr], yG_all[m_val], yG_all[m_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2099c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensors ready with shapes:\n",
      "  X_tr: (12635, 48, 48, 1) | X_val: (4198, 48, 48, 1) | X_te: (4167, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTensors ready with shapes:\")\n",
    "print(\"  X_tr:\", X_tr.shape, \"| X_val:\", X_val.shape, \"| X_te:\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed7109cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_age     = compute_class_weight(\"balanced\", classes=np.arange(yA_tr.shape[1]), y=np.argmax(yA_tr,1)).astype('float32')\n",
    "if USE_GENDER:\n",
    "    cw_gender = compute_class_weight(\"balanced\", classes=np.arange(2), y=yG_tr).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e3be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_train = {\n",
    "    'emotion_output':   np.ones(len(yE_tr), dtype='float32'),\n",
    "    'age_output':       cw_age[np.argmax(yA_tr, axis=1)],\n",
    "    'ethnicity_output': np.ones(len(yT_tr), dtype='float32'),\n",
    "}\n",
    "sw_val  = {k: np.ones(len(X_val), dtype='float32') for k in sw_train.keys()}\n",
    "sw_test = {k: np.ones(len(X_te),  dtype='float32') for k in sw_train.keys()}\n",
    "if USE_GENDER:\n",
    "    sw_train['gender_output'] = cw_gender[yG_tr]\n",
    "    sw_val['gender_output']   = np.ones(len(X_val), dtype='float32')\n",
    "    sw_test['gender_output']  = np.ones(len(X_te),  dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bd94f6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "AUG = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.08),\n",
    "    tf.keras.layers.RandomZoom(0.12),\n",
    "    tf.keras.layers.RandomContrast(0.12),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78b71417",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def make_ds(X, yE, yA, yT, yG=None, sw=None, batch=64, shuffle=False):\n",
    "    n = len(X)\n",
    "    def gen():\n",
    "        for i in range(n):\n",
    "            x = X[i]\n",
    "            y = {\n",
    "                'emotion_output':   yE[i].astype('float32'),\n",
    "                'age_output':       yA[i].astype('float32'),\n",
    "                'ethnicity_output': yT[i].astype('float32'),\n",
    "            }\n",
    "            if yG is not None: y['gender_output'] = np.asarray([yG[i]], dtype=np.float32)\n",
    "            if sw is None: yield x.astype('float32'), y\n",
    "            else:\n",
    "                w = {k: np.float32(sw[k][i]) for k in sw.keys()}\n",
    "                yield x.astype('float32'), y, w\n",
    "\n",
    "    sig_x = tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, IMG_CH), dtype=tf.float32)\n",
    "    sig_y = {\n",
    "        'emotion_output':   tf.TensorSpec(shape=(yE.shape[1],), dtype=tf.float32),\n",
    "        'age_output':       tf.TensorSpec(shape=(yA.shape[1],), dtype=tf.float32),\n",
    "        'ethnicity_output': tf.TensorSpec(shape=(yT.shape[1],), dtype=tf.float32),\n",
    "    }\n",
    "    if yG is not None: sig_y['gender_output'] = tf.TensorSpec(shape=(1,), dtype=tf.float32)\n",
    "    if sw is None:\n",
    "        output_signature = (sig_x, sig_y)\n",
    "    else:\n",
    "        sig_w = {k: tf.TensorSpec(shape=(), dtype=tf.float32) for k in sw.keys()}\n",
    "        output_signature = (sig_x, sig_y, sig_w)\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(len(X), 8192), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        def _aug(x, *rest):\n",
    "            return (AUG(x, training=True),) + rest\n",
    "        ds = ds.map(_aug, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "539035d4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_ds = make_ds(X_tr, yE_tr, yA_tr, yT_tr, yG_tr if USE_GENDER else None,\n",
    "                   sw=sw_train, batch=BATCH_SIZE_CNN, shuffle=True)\n",
    "val_ds   = make_ds(X_val, yE_val, yA_val, yT_val, yG_val if USE_GENDER else None,\n",
    "                   sw=sw_val,   batch=BATCH_SIZE_CNN)\n",
    "test_ds  = make_ds(X_te, yE_te, yA_te, yT_te, yG_te if USE_GENDER else None,\n",
    "                   sw=sw_test,  batch=BATCH_SIZE_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a71fcde0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters):\n",
    "    x = Conv2D(filters, (3,3), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x); x = ReLU()(x)\n",
    "    x = Conv2D(filters, (3,3), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x); x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b91f5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, IMG_CH), name=\"input_layer\")\n",
    "x = conv_block(inputs, 64)\n",
    "x = conv_block(x, 128)\n",
    "x = conv_block(x, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40ce2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "ch  = tf.keras.layers.Dense(256, activation=\"relu\")(gap)\n",
    "ch  = tf.keras.layers.Dense(int(x.shape[-1]), activation=\"sigmoid\")(ch)\n",
    "ch  = tf.keras.layers.Reshape((1,1,int(x.shape[-1])))(ch)\n",
    "x   = tf.keras.layers.Multiply()([x, ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e205fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.30)(x)\n",
    "shared = Dense(512, activation=\"relu\")(x)\n",
    "shared = BatchNormalization()(shared)\n",
    "shared = Dropout(0.30)(shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96a78b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_output   = Dense(len(EMOS),               activation='softmax', name='emotion_output')(shared)\n",
    "age_output       = Dense(3,                        activation='softmax', name='age_output')(shared)\n",
    "ethnicity_output = Dense(len(eth_le.classes_),     activation='softmax', name='ethnicity_output')(shared)\n",
    "outputs = {'emotion_output': emotion_output, 'age_output': age_output, 'ethnicity_output': ethnicity_output}\n",
    "if USE_GENDER:\n",
    "    gender_output = Dense(1, activation='sigmoid', name='gender_output')(shared)\n",
    "    outputs['gender_output'] = gender_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84757e35",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cnn_model = Model(inputs=inputs, outputs=outputs, name=\"CNN_MTL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "502a5af2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "emo_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.0)\n",
    "age_loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)\n",
    "eth_loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0669b524",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "callbacks_A = [\n",
    "    ModelCheckpoint(\"masked_face_multitask_model.keras\",\n",
    "                    monitor='val_emotion_output_accuracy', mode='max',\n",
    "                    save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_emotion_output_accuracy', mode='max',\n",
    "                      factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n",
    "    CSVLogger(\"training_log.csv\", append=False)\n",
    "]\n",
    "callbacks_B = [\n",
    "    ModelCheckpoint(\"masked_face_multitask_model.keras\",\n",
    "                    monitor='val_emotion_output_accuracy', mode='max',\n",
    "                    save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_emotion_output_accuracy', mode='max',\n",
    "                      factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n",
    "    EarlyStopping(monitor='val_emotion_output_accuracy', mode='max',\n",
    "                  patience=10, min_delta=1e-3, restore_best_weights=True, verbose=1),\n",
    "    CSVLogger(\"training_log.csv\", append=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9de8bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CNN  Stage A (emotion-only, 40 epochs)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n CNN  Stage A (emotion-only, 40 epochs)\")\n",
    "losses = {'emotion_output': emo_loss, 'age_output': age_loss, 'ethnicity_output': eth_loss}\n",
    "metrics= {'emotion_output': 'accuracy','age_output': 'accuracy','ethnicity_output': 'accuracy'}\n",
    "loss_w = {'emotion_output': 1.0, 'age_output': 0.0, 'ethnicity_output': 0.0}\n",
    "if USE_GENDER:\n",
    "    losses['gender_output'] = 'binary_crossentropy'\n",
    "    metrics['gender_output'] = 'accuracy'\n",
    "    loss_w['gender_output'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d0e4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss=losses, loss_weights=loss_w, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae14095",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "    198/Unknown \u001b[1m82s\u001b[0m 389ms/step - age_output_accuracy: 0.3336 - age_output_loss: 1.4828 - emotion_output_accuracy: 0.1623 - emotion_output_loss: 2.3862 - ethnicity_output_accuracy: 0.2823 - ethnicity_output_loss: 2.4462 - gender_output_accuracy: 0.4455 - gender_output_loss: 0.9316 - loss: 2.3862\n",
      "Epoch 1: val_emotion_output_accuracy improved from None to 0.13435, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 418ms/step - age_output_accuracy: 0.3430 - age_output_loss: 1.4746 - emotion_output_accuracy: 0.1618 - emotion_output_loss: 2.2697 - ethnicity_output_accuracy: 0.2864 - ethnicity_output_loss: 2.5160 - gender_output_accuracy: 0.4393 - gender_output_loss: 0.8842 - loss: 2.2811 - val_age_output_accuracy: 0.2477 - val_age_output_loss: 1.5866 - val_emotion_output_accuracy: 0.1343 - val_emotion_output_loss: 1.9796 - val_ethnicity_output_accuracy: 0.7494 - val_ethnicity_output_loss: 1.2368 - val_gender_output_accuracy: 0.1879 - val_gender_output_loss: 0.9943 - val_loss: 2.0099 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - age_output_accuracy: 0.3347 - age_output_loss: 1.6473 - emotion_output_accuracy: 0.1810 - emotion_output_loss: 2.1391 - ethnicity_output_accuracy: 0.2050 - ethnicity_output_loss: 2.5008 - gender_output_accuracy: 0.4450 - gender_output_loss: 0.8751 - loss: 2.1391\n",
      "Epoch 2: val_emotion_output_accuracy improved from 0.13435 to 0.19223, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 504ms/step - age_output_accuracy: 0.3288 - age_output_loss: 1.6558 - emotion_output_accuracy: 0.1832 - emotion_output_loss: 2.1107 - ethnicity_output_accuracy: 0.1873 - ethnicity_output_loss: 2.4886 - gender_output_accuracy: 0.4795 - gender_output_loss: 0.8389 - loss: 2.1216 - val_age_output_accuracy: 0.1136 - val_age_output_loss: 1.5344 - val_emotion_output_accuracy: 0.1922 - val_emotion_output_loss: 1.9755 - val_ethnicity_output_accuracy: 0.6151 - val_ethnicity_output_loss: 1.3826 - val_gender_output_accuracy: 0.8111 - val_gender_output_loss: 0.5137 - val_loss: 2.0055 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - age_output_accuracy: 0.3458 - age_output_loss: 1.5404 - emotion_output_accuracy: 0.1950 - emotion_output_loss: 2.0524 - ethnicity_output_accuracy: 0.1649 - ethnicity_output_loss: 2.5914 - gender_output_accuracy: 0.5135 - gender_output_loss: 0.8294 - loss: 2.0524\n",
      "Epoch 3: val_emotion_output_accuracy did not improve from 0.19223\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 558ms/step - age_output_accuracy: 0.3425 - age_output_loss: 1.5307 - emotion_output_accuracy: 0.2081 - emotion_output_loss: 2.0200 - ethnicity_output_accuracy: 0.1592 - ethnicity_output_loss: 2.5115 - gender_output_accuracy: 0.5112 - gender_output_loss: 0.8151 - loss: 2.0304 - val_age_output_accuracy: 0.7296 - val_age_output_loss: 1.0681 - val_emotion_output_accuracy: 0.1577 - val_emotion_output_loss: 2.3868 - val_ethnicity_output_accuracy: 0.3878 - val_ethnicity_output_loss: 1.7144 - val_gender_output_accuracy: 0.1879 - val_gender_output_loss: 1.3833 - val_loss: 2.4237 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - age_output_accuracy: 0.3191 - age_output_loss: 1.5649 - emotion_output_accuracy: 0.2383 - emotion_output_loss: 1.9490 - ethnicity_output_accuracy: 0.1819 - ethnicity_output_loss: 2.3865 - gender_output_accuracy: 0.4868 - gender_output_loss: 0.8465 - loss: 1.9490\n",
      "Epoch 4: val_emotion_output_accuracy did not improve from 0.19223\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 571ms/step - age_output_accuracy: 0.3228 - age_output_loss: 1.5500 - emotion_output_accuracy: 0.2404 - emotion_output_loss: 1.9174 - ethnicity_output_accuracy: 0.1926 - ethnicity_output_loss: 2.3610 - gender_output_accuracy: 0.4859 - gender_output_loss: 0.8435 - loss: 1.9283 - val_age_output_accuracy: 0.5395 - val_age_output_loss: 1.5302 - val_emotion_output_accuracy: 0.1675 - val_emotion_output_loss: 2.3953 - val_ethnicity_output_accuracy: 0.1339 - val_ethnicity_output_loss: 3.8838 - val_gender_output_accuracy: 0.8101 - val_gender_output_loss: 0.5088 - val_loss: 2.4290 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - age_output_accuracy: 0.3387 - age_output_loss: 1.5594 - emotion_output_accuracy: 0.2651 - emotion_output_loss: 1.8677 - ethnicity_output_accuracy: 0.2039 - ethnicity_output_loss: 2.3439 - gender_output_accuracy: 0.4841 - gender_output_loss: 0.8513 - loss: 1.8677\n",
      "Epoch 5: val_emotion_output_accuracy improved from 0.19223 to 0.23630, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 510ms/step - age_output_accuracy: 0.3463 - age_output_loss: 1.5679 - emotion_output_accuracy: 0.2648 - emotion_output_loss: 1.8508 - ethnicity_output_accuracy: 0.2029 - ethnicity_output_loss: 2.3603 - gender_output_accuracy: 0.4915 - gender_output_loss: 0.8399 - loss: 1.8604 - val_age_output_accuracy: 0.3020 - val_age_output_loss: 1.6716 - val_emotion_output_accuracy: 0.2363 - val_emotion_output_loss: 2.0123 - val_ethnicity_output_accuracy: 0.1939 - val_ethnicity_output_loss: 2.4439 - val_gender_output_accuracy: 0.2349 - val_gender_output_loss: 1.1286 - val_loss: 2.0418 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - age_output_accuracy: 0.3517 - age_output_loss: 1.6301 - emotion_output_accuracy: 0.2799 - emotion_output_loss: 1.8168 - ethnicity_output_accuracy: 0.1962 - ethnicity_output_loss: 2.3631 - gender_output_accuracy: 0.4768 - gender_output_loss: 0.8713 - loss: 1.8168\n",
      "Epoch 6: val_emotion_output_accuracy did not improve from 0.23630\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 419ms/step - age_output_accuracy: 0.3592 - age_output_loss: 1.5869 - emotion_output_accuracy: 0.2878 - emotion_output_loss: 1.7925 - ethnicity_output_accuracy: 0.1907 - ethnicity_output_loss: 2.3546 - gender_output_accuracy: 0.4790 - gender_output_loss: 0.8611 - loss: 1.8013 - val_age_output_accuracy: 0.7182 - val_age_output_loss: 2.1220 - val_emotion_output_accuracy: 0.1646 - val_emotion_output_loss: 2.7036 - val_ethnicity_output_accuracy: 0.1327 - val_ethnicity_output_loss: 9.7368 - val_gender_output_accuracy: 0.5900 - val_gender_output_loss: 0.6899 - val_loss: 2.7420 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - age_output_accuracy: 0.3611 - age_output_loss: 1.5407 - emotion_output_accuracy: 0.3055 - emotion_output_loss: 1.7685 - ethnicity_output_accuracy: 0.1852 - ethnicity_output_loss: 2.4077 - gender_output_accuracy: 0.4877 - gender_output_loss: 0.8837 - loss: 1.7685\n",
      "Epoch 7: val_emotion_output_accuracy improved from 0.23630 to 0.27465, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 361ms/step - age_output_accuracy: 0.3574 - age_output_loss: 1.5742 - emotion_output_accuracy: 0.3068 - emotion_output_loss: 1.7546 - ethnicity_output_accuracy: 0.1822 - ethnicity_output_loss: 2.4015 - gender_output_accuracy: 0.5003 - gender_output_loss: 0.8439 - loss: 1.7640 - val_age_output_accuracy: 0.4783 - val_age_output_loss: 1.2995 - val_emotion_output_accuracy: 0.2747 - val_emotion_output_loss: 1.8278 - val_ethnicity_output_accuracy: 0.1060 - val_ethnicity_output_loss: 4.1019 - val_gender_output_accuracy: 0.7706 - val_gender_output_loss: 0.5334 - val_loss: 1.8548 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - age_output_accuracy: 0.3551 - age_output_loss: 1.5875 - emotion_output_accuracy: 0.3123 - emotion_output_loss: 1.7516 - ethnicity_output_accuracy: 0.1683 - ethnicity_output_loss: 2.4689 - gender_output_accuracy: 0.5031 - gender_output_loss: 0.8407 - loss: 1.7516\n",
      "Epoch 8: val_emotion_output_accuracy improved from 0.27465 to 0.35469, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 360ms/step - age_output_accuracy: 0.3614 - age_output_loss: 1.5183 - emotion_output_accuracy: 0.3243 - emotion_output_loss: 1.7199 - ethnicity_output_accuracy: 0.1627 - ethnicity_output_loss: 2.4435 - gender_output_accuracy: 0.4973 - gender_output_loss: 0.8436 - loss: 1.7291 - val_age_output_accuracy: 0.4104 - val_age_output_loss: 1.2839 - val_emotion_output_accuracy: 0.3547 - val_emotion_output_loss: 1.6787 - val_ethnicity_output_accuracy: 0.0831 - val_ethnicity_output_loss: 2.0182 - val_gender_output_accuracy: 0.7010 - val_gender_output_loss: 0.5958 - val_loss: 1.7026 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - age_output_accuracy: 0.3651 - age_output_loss: 1.5617 - emotion_output_accuracy: 0.3336 - emotion_output_loss: 1.7069 - ethnicity_output_accuracy: 0.1671 - ethnicity_output_loss: 2.4015 - gender_output_accuracy: 0.5020 - gender_output_loss: 0.8782 - loss: 1.7069\n",
      "Epoch 9: val_emotion_output_accuracy did not improve from 0.35469\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 295ms/step - age_output_accuracy: 0.3697 - age_output_loss: 1.5605 - emotion_output_accuracy: 0.3384 - emotion_output_loss: 1.6862 - ethnicity_output_accuracy: 0.1689 - ethnicity_output_loss: 2.3672 - gender_output_accuracy: 0.5041 - gender_output_loss: 0.8565 - loss: 1.6940 - val_age_output_accuracy: 0.3811 - val_age_output_loss: 1.3049 - val_emotion_output_accuracy: 0.3185 - val_emotion_output_loss: 1.8452 - val_ethnicity_output_accuracy: 0.1205 - val_ethnicity_output_loss: 2.5847 - val_gender_output_accuracy: 0.5312 - val_gender_output_loss: 0.6943 - val_loss: 1.8714 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - age_output_accuracy: 0.3627 - age_output_loss: 1.5635 - emotion_output_accuracy: 0.3551 - emotion_output_loss: 1.6564 - ethnicity_output_accuracy: 0.1908 - ethnicity_output_loss: 2.2922 - gender_output_accuracy: 0.4867 - gender_output_loss: 0.8944 - loss: 1.6564\n",
      "Epoch 10: val_emotion_output_accuracy did not improve from 0.35469\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 274ms/step - age_output_accuracy: 0.3616 - age_output_loss: 1.5605 - emotion_output_accuracy: 0.3523 - emotion_output_loss: 1.6536 - ethnicity_output_accuracy: 0.1873 - ethnicity_output_loss: 2.2931 - gender_output_accuracy: 0.4965 - gender_output_loss: 0.8665 - loss: 1.6614 - val_age_output_accuracy: 0.2520 - val_age_output_loss: 1.7075 - val_emotion_output_accuracy: 0.3225 - val_emotion_output_loss: 1.7757 - val_ethnicity_output_accuracy: 0.1008 - val_ethnicity_output_loss: 2.2549 - val_gender_output_accuracy: 0.4090 - val_gender_output_loss: 0.8626 - val_loss: 1.8011 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - age_output_accuracy: 0.3537 - age_output_loss: 1.6483 - emotion_output_accuracy: 0.3635 - emotion_output_loss: 1.6355 - ethnicity_output_accuracy: 0.1893 - ethnicity_output_loss: 2.3084 - gender_output_accuracy: 0.5060 - gender_output_loss: 0.8666 - loss: 1.6355\n",
      "Epoch 11: val_emotion_output_accuracy did not improve from 0.35469\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 322ms/step - age_output_accuracy: 0.3567 - age_output_loss: 1.5851 - emotion_output_accuracy: 0.3668 - emotion_output_loss: 1.6290 - ethnicity_output_accuracy: 0.1905 - ethnicity_output_loss: 2.2919 - gender_output_accuracy: 0.5172 - gender_output_loss: 0.8531 - loss: 1.6379 - val_age_output_accuracy: 0.5281 - val_age_output_loss: 1.2890 - val_emotion_output_accuracy: 0.2932 - val_emotion_output_loss: 1.7568 - val_ethnicity_output_accuracy: 0.2365 - val_ethnicity_output_loss: 1.8595 - val_gender_output_accuracy: 0.3228 - val_gender_output_loss: 0.9185 - val_loss: 1.7823 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - age_output_accuracy: 0.3563 - age_output_loss: 1.5737 - emotion_output_accuracy: 0.3746 - emotion_output_loss: 1.6182 - ethnicity_output_accuracy: 0.1993 - ethnicity_output_loss: 2.2588 - gender_output_accuracy: 0.5119 - gender_output_loss: 0.8631 - loss: 1.6182\n",
      "Epoch 12: val_emotion_output_accuracy did not improve from 0.35469\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 289ms/step - age_output_accuracy: 0.3571 - age_output_loss: 1.5804 - emotion_output_accuracy: 0.3822 - emotion_output_loss: 1.5964 - ethnicity_output_accuracy: 0.1931 - ethnicity_output_loss: 2.2825 - gender_output_accuracy: 0.5089 - gender_output_loss: 0.8532 - loss: 1.6047 - val_age_output_accuracy: 0.3225 - val_age_output_loss: 1.4166 - val_emotion_output_accuracy: 0.3525 - val_emotion_output_loss: 1.7083 - val_ethnicity_output_accuracy: 0.1343 - val_ethnicity_output_loss: 2.3230 - val_gender_output_accuracy: 0.2151 - val_gender_output_loss: 1.0251 - val_loss: 1.7322 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - age_output_accuracy: 0.3496 - age_output_loss: 1.5323 - emotion_output_accuracy: 0.4036 - emotion_output_loss: 1.5524 - ethnicity_output_accuracy: 0.1883 - ethnicity_output_loss: 2.2964 - gender_output_accuracy: 0.5063 - gender_output_loss: 0.8605 - loss: 1.5524\n",
      "Epoch 13: val_emotion_output_accuracy did not improve from 0.35469\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 660ms/step - age_output_accuracy: 0.3513 - age_output_loss: 1.5319 - emotion_output_accuracy: 0.4102 - emotion_output_loss: 1.5348 - ethnicity_output_accuracy: 0.1898 - ethnicity_output_loss: 2.2928 - gender_output_accuracy: 0.4991 - gender_output_loss: 0.8696 - loss: 1.5426 - val_age_output_accuracy: 0.3764 - val_age_output_loss: 1.2747 - val_emotion_output_accuracy: 0.3356 - val_emotion_output_loss: 1.6591 - val_ethnicity_output_accuracy: 0.4736 - val_ethnicity_output_loss: 1.5482 - val_gender_output_accuracy: 0.5746 - val_gender_output_loss: 0.6817 - val_loss: 1.6841 - learning_rate: 5.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - age_output_accuracy: 0.3560 - age_output_loss: 1.5806 - emotion_output_accuracy: 0.4190 - emotion_output_loss: 1.5219 - ethnicity_output_accuracy: 0.1975 - ethnicity_output_loss: 2.2915 - gender_output_accuracy: 0.4882 - gender_output_loss: 0.9095 - loss: 1.5219\n",
      "Epoch 14: val_emotion_output_accuracy improved from 0.35469 to 0.41139, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 510ms/step - age_output_accuracy: 0.3520 - age_output_loss: 1.5637 - emotion_output_accuracy: 0.4234 - emotion_output_loss: 1.5091 - ethnicity_output_accuracy: 0.2017 - ethnicity_output_loss: 2.2684 - gender_output_accuracy: 0.4951 - gender_output_loss: 0.8883 - loss: 1.5159 - val_age_output_accuracy: 0.5653 - val_age_output_loss: 1.0097 - val_emotion_output_accuracy: 0.4114 - val_emotion_output_loss: 1.5384 - val_ethnicity_output_accuracy: 0.1289 - val_ethnicity_output_loss: 2.9682 - val_gender_output_accuracy: 0.5665 - val_gender_output_loss: 0.7286 - val_loss: 1.5603 - learning_rate: 5.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - age_output_accuracy: 0.3520 - age_output_loss: 1.5606 - emotion_output_accuracy: 0.4248 - emotion_output_loss: 1.5050 - ethnicity_output_accuracy: 0.1979 - ethnicity_output_loss: 2.2688 - gender_output_accuracy: 0.4911 - gender_output_loss: 0.8914 - loss: 1.5050\n",
      "Epoch 15: val_emotion_output_accuracy did not improve from 0.41139\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 357ms/step - age_output_accuracy: 0.3513 - age_output_loss: 1.5566 - emotion_output_accuracy: 0.4290 - emotion_output_loss: 1.4893 - ethnicity_output_accuracy: 0.1949 - ethnicity_output_loss: 2.2512 - gender_output_accuracy: 0.4860 - gender_output_loss: 0.9006 - loss: 1.4974 - val_age_output_accuracy: 0.4714 - val_age_output_loss: 1.1405 - val_emotion_output_accuracy: 0.3483 - val_emotion_output_loss: 1.6736 - val_ethnicity_output_accuracy: 0.2184 - val_ethnicity_output_loss: 1.8767 - val_gender_output_accuracy: 0.3952 - val_gender_output_loss: 0.9128 - val_loss: 1.6980 - learning_rate: 5.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - age_output_accuracy: 0.3484 - age_output_loss: 1.5497 - emotion_output_accuracy: 0.4423 - emotion_output_loss: 1.4663 - ethnicity_output_accuracy: 0.1973 - ethnicity_output_loss: 2.2554 - gender_output_accuracy: 0.4988 - gender_output_loss: 0.9059 - loss: 1.4663\n",
      "Epoch 16: val_emotion_output_accuracy did not improve from 0.41139\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 566ms/step - age_output_accuracy: 0.3452 - age_output_loss: 1.5723 - emotion_output_accuracy: 0.4439 - emotion_output_loss: 1.4561 - ethnicity_output_accuracy: 0.1938 - ethnicity_output_loss: 2.2598 - gender_output_accuracy: 0.4949 - gender_output_loss: 0.9038 - loss: 1.4640 - val_age_output_accuracy: 0.4033 - val_age_output_loss: 1.2371 - val_emotion_output_accuracy: 0.3733 - val_emotion_output_loss: 1.5770 - val_ethnicity_output_accuracy: 0.0996 - val_ethnicity_output_loss: 1.9913 - val_gender_output_accuracy: 0.4235 - val_gender_output_loss: 0.7921 - val_loss: 1.5999 - learning_rate: 5.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652ms/step - age_output_accuracy: 0.3531 - age_output_loss: 1.6019 - emotion_output_accuracy: 0.4428 - emotion_output_loss: 1.4558 - ethnicity_output_accuracy: 0.1924 - ethnicity_output_loss: 2.2818 - gender_output_accuracy: 0.5040 - gender_output_loss: 0.8662 - loss: 1.4558\n",
      "Epoch 17: val_emotion_output_accuracy did not improve from 0.41139\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 687ms/step - age_output_accuracy: 0.3509 - age_output_loss: 1.5613 - emotion_output_accuracy: 0.4461 - emotion_output_loss: 1.4505 - ethnicity_output_accuracy: 0.1955 - ethnicity_output_loss: 2.2674 - gender_output_accuracy: 0.4964 - gender_output_loss: 0.8770 - loss: 1.4583 - val_age_output_accuracy: 0.3945 - val_age_output_loss: 1.2144 - val_emotion_output_accuracy: 0.3940 - val_emotion_output_loss: 1.5450 - val_ethnicity_output_accuracy: 0.2456 - val_ethnicity_output_loss: 1.9895 - val_gender_output_accuracy: 0.6251 - val_gender_output_loss: 0.6899 - val_loss: 1.5674 - learning_rate: 5.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - age_output_accuracy: 0.3395 - age_output_loss: 1.5942 - emotion_output_accuracy: 0.4478 - emotion_output_loss: 1.4477 - ethnicity_output_accuracy: 0.1966 - ethnicity_output_loss: 2.2861 - gender_output_accuracy: 0.4936 - gender_output_loss: 0.8997 - loss: 1.4477\n",
      "Epoch 18: val_emotion_output_accuracy did not improve from 0.41139\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 712ms/step - age_output_accuracy: 0.3421 - age_output_loss: 1.5426 - emotion_output_accuracy: 0.4524 - emotion_output_loss: 1.4379 - ethnicity_output_accuracy: 0.1999 - ethnicity_output_loss: 2.2655 - gender_output_accuracy: 0.4820 - gender_output_loss: 0.9033 - loss: 1.4447 - val_age_output_accuracy: 0.2006 - val_age_output_loss: 1.7842 - val_emotion_output_accuracy: 0.3923 - val_emotion_output_loss: 1.6391 - val_ethnicity_output_accuracy: 0.1846 - val_ethnicity_output_loss: 1.9376 - val_gender_output_accuracy: 0.6432 - val_gender_output_loss: 0.6602 - val_loss: 1.6625 - learning_rate: 5.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - age_output_accuracy: 0.3501 - age_output_loss: 1.5463 - emotion_output_accuracy: 0.4718 - emotion_output_loss: 1.4028 - ethnicity_output_accuracy: 0.1894 - ethnicity_output_loss: 2.2686 - gender_output_accuracy: 0.4792 - gender_output_loss: 0.9331 - loss: 1.4028\n",
      "Epoch 19: val_emotion_output_accuracy improved from 0.41139 to 0.43711, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 775ms/step - age_output_accuracy: 0.3522 - age_output_loss: 1.5230 - emotion_output_accuracy: 0.4704 - emotion_output_loss: 1.3979 - ethnicity_output_accuracy: 0.1963 - ethnicity_output_loss: 2.2417 - gender_output_accuracy: 0.4851 - gender_output_loss: 0.9292 - loss: 1.4049 - val_age_output_accuracy: 0.3766 - val_age_output_loss: 1.2896 - val_emotion_output_accuracy: 0.4371 - val_emotion_output_loss: 1.4802 - val_ethnicity_output_accuracy: 0.1541 - val_ethnicity_output_loss: 1.9956 - val_gender_output_accuracy: 0.3614 - val_gender_output_loss: 0.9221 - val_loss: 1.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - age_output_accuracy: 0.3531 - age_output_loss: 1.5123 - emotion_output_accuracy: 0.4777 - emotion_output_loss: 1.3851 - ethnicity_output_accuracy: 0.2091 - ethnicity_output_loss: 2.2246 - gender_output_accuracy: 0.4845 - gender_output_loss: 0.9439 - loss: 1.3851\n",
      "Epoch 20: val_emotion_output_accuracy improved from 0.43711 to 0.45164, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 683ms/step - age_output_accuracy: 0.3520 - age_output_loss: 1.5329 - emotion_output_accuracy: 0.4818 - emotion_output_loss: 1.3724 - ethnicity_output_accuracy: 0.2075 - ethnicity_output_loss: 2.2351 - gender_output_accuracy: 0.4769 - gender_output_loss: 0.9409 - loss: 1.3796 - val_age_output_accuracy: 0.3809 - val_age_output_loss: 1.3174 - val_emotion_output_accuracy: 0.4516 - val_emotion_output_loss: 1.4243 - val_ethnicity_output_accuracy: 0.2130 - val_ethnicity_output_loss: 1.8455 - val_gender_output_accuracy: 0.5088 - val_gender_output_loss: 0.7713 - val_loss: 1.4451 - learning_rate: 2.5000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - age_output_accuracy: 0.3569 - age_output_loss: 1.5643 - emotion_output_accuracy: 0.4790 - emotion_output_loss: 1.3679 - ethnicity_output_accuracy: 0.2083 - ethnicity_output_loss: 2.2578 - gender_output_accuracy: 0.4881 - gender_output_loss: 0.8961 - loss: 1.3679\n",
      "Epoch 21: val_emotion_output_accuracy did not improve from 0.45164\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 631ms/step - age_output_accuracy: 0.3536 - age_output_loss: 1.5221 - emotion_output_accuracy: 0.4828 - emotion_output_loss: 1.3559 - ethnicity_output_accuracy: 0.2107 - ethnicity_output_loss: 2.2393 - gender_output_accuracy: 0.4819 - gender_output_loss: 0.9148 - loss: 1.3627 - val_age_output_accuracy: 0.5091 - val_age_output_loss: 1.1132 - val_emotion_output_accuracy: 0.4393 - val_emotion_output_loss: 1.4926 - val_ethnicity_output_accuracy: 0.1324 - val_ethnicity_output_loss: 2.1851 - val_gender_output_accuracy: 0.4931 - val_gender_output_loss: 0.8084 - val_loss: 1.5145 - learning_rate: 2.5000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - age_output_accuracy: 0.3466 - age_output_loss: 1.4980 - emotion_output_accuracy: 0.4992 - emotion_output_loss: 1.3474 - ethnicity_output_accuracy: 0.2134 - ethnicity_output_loss: 2.2354 - gender_output_accuracy: 0.4875 - gender_output_loss: 0.9628 - loss: 1.3474\n",
      "Epoch 22: val_emotion_output_accuracy did not improve from 0.45164\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 580ms/step - age_output_accuracy: 0.3463 - age_output_loss: 1.5179 - emotion_output_accuracy: 0.4960 - emotion_output_loss: 1.3417 - ethnicity_output_accuracy: 0.2108 - ethnicity_output_loss: 2.2379 - gender_output_accuracy: 0.4905 - gender_output_loss: 0.9370 - loss: 1.3476 - val_age_output_accuracy: 0.4800 - val_age_output_loss: 1.0617 - val_emotion_output_accuracy: 0.3683 - val_emotion_output_loss: 1.6075 - val_ethnicity_output_accuracy: 0.1577 - val_ethnicity_output_loss: 1.9086 - val_gender_output_accuracy: 0.4576 - val_gender_output_loss: 0.8057 - val_loss: 1.6315 - learning_rate: 2.5000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - age_output_accuracy: 0.3497 - age_output_loss: 1.5203 - emotion_output_accuracy: 0.4998 - emotion_output_loss: 1.3416 - ethnicity_output_accuracy: 0.2081 - ethnicity_output_loss: 2.2479 - gender_output_accuracy: 0.4847 - gender_output_loss: 0.9406 - loss: 1.3416\n",
      "Epoch 23: val_emotion_output_accuracy did not improve from 0.45164\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 500ms/step - age_output_accuracy: 0.3473 - age_output_loss: 1.5125 - emotion_output_accuracy: 0.4996 - emotion_output_loss: 1.3359 - ethnicity_output_accuracy: 0.2100 - ethnicity_output_loss: 2.2289 - gender_output_accuracy: 0.4840 - gender_output_loss: 0.9247 - loss: 1.3426 - val_age_output_accuracy: 0.3340 - val_age_output_loss: 1.4124 - val_emotion_output_accuracy: 0.4162 - val_emotion_output_loss: 1.5915 - val_ethnicity_output_accuracy: 0.2508 - val_ethnicity_output_loss: 1.7336 - val_gender_output_accuracy: 0.3511 - val_gender_output_loss: 0.9737 - val_loss: 1.6155 - learning_rate: 2.5000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - age_output_accuracy: 0.3531 - age_output_loss: 1.5267 - emotion_output_accuracy: 0.5085 - emotion_output_loss: 1.3185 - ethnicity_output_accuracy: 0.2064 - ethnicity_output_loss: 2.2338 - gender_output_accuracy: 0.4886 - gender_output_loss: 0.9346 - loss: 1.3185\n",
      "Epoch 24: val_emotion_output_accuracy improved from 0.45164 to 0.46070, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 766ms/step - age_output_accuracy: 0.3459 - age_output_loss: 1.5348 - emotion_output_accuracy: 0.5080 - emotion_output_loss: 1.3155 - ethnicity_output_accuracy: 0.2075 - ethnicity_output_loss: 2.2193 - gender_output_accuracy: 0.4914 - gender_output_loss: 0.9259 - loss: 1.3211 - val_age_output_accuracy: 0.3726 - val_age_output_loss: 1.2635 - val_emotion_output_accuracy: 0.4607 - val_emotion_output_loss: 1.4168 - val_ethnicity_output_accuracy: 0.1389 - val_ethnicity_output_loss: 2.1348 - val_gender_output_accuracy: 0.5222 - val_gender_output_loss: 0.7705 - val_loss: 1.4375 - learning_rate: 2.5000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - age_output_accuracy: 0.3479 - age_output_loss: 1.4423 - emotion_output_accuracy: 0.5083 - emotion_output_loss: 1.3070 - ethnicity_output_accuracy: 0.1977 - ethnicity_output_loss: 2.2384 - gender_output_accuracy: 0.4924 - gender_output_loss: 0.9342 - loss: 1.3070\n",
      "Epoch 25: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 314ms/step - age_output_accuracy: 0.3449 - age_output_loss: 1.4778 - emotion_output_accuracy: 0.5114 - emotion_output_loss: 1.2980 - ethnicity_output_accuracy: 0.2016 - ethnicity_output_loss: 2.2151 - gender_output_accuracy: 0.4927 - gender_output_loss: 0.9176 - loss: 1.3044 - val_age_output_accuracy: 0.3783 - val_age_output_loss: 1.3144 - val_emotion_output_accuracy: 0.4190 - val_emotion_output_loss: 1.4964 - val_ethnicity_output_accuracy: 0.2820 - val_ethnicity_output_loss: 1.7068 - val_gender_output_accuracy: 0.3797 - val_gender_output_loss: 0.9003 - val_loss: 1.5189 - learning_rate: 2.5000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - age_output_accuracy: 0.3394 - age_output_loss: 1.5122 - emotion_output_accuracy: 0.5177 - emotion_output_loss: 1.2888 - ethnicity_output_accuracy: 0.2065 - ethnicity_output_loss: 2.2257 - gender_output_accuracy: 0.4985 - gender_output_loss: 0.9126 - loss: 1.2888\n",
      "Epoch 26: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 259ms/step - age_output_accuracy: 0.3371 - age_output_loss: 1.5118 - emotion_output_accuracy: 0.5172 - emotion_output_loss: 1.2816 - ethnicity_output_accuracy: 0.2044 - ethnicity_output_loss: 2.2085 - gender_output_accuracy: 0.4958 - gender_output_loss: 0.9058 - loss: 1.2877 - val_age_output_accuracy: 0.2544 - val_age_output_loss: 1.5295 - val_emotion_output_accuracy: 0.4497 - val_emotion_output_loss: 1.4353 - val_ethnicity_output_accuracy: 0.2873 - val_ethnicity_output_loss: 1.6215 - val_gender_output_accuracy: 0.4466 - val_gender_output_loss: 0.8366 - val_loss: 1.4566 - learning_rate: 2.5000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - age_output_accuracy: 0.3357 - age_output_loss: 1.5700 - emotion_output_accuracy: 0.5215 - emotion_output_loss: 1.2856 - ethnicity_output_accuracy: 0.1983 - ethnicity_output_loss: 2.2538 - gender_output_accuracy: 0.4922 - gender_output_loss: 0.9302 - loss: 1.2856\n",
      "Epoch 27: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 257ms/step - age_output_accuracy: 0.3415 - age_output_loss: 1.5028 - emotion_output_accuracy: 0.5196 - emotion_output_loss: 1.2786 - ethnicity_output_accuracy: 0.2054 - ethnicity_output_loss: 2.2297 - gender_output_accuracy: 0.4858 - gender_output_loss: 0.9358 - loss: 1.2837 - val_age_output_accuracy: 0.3788 - val_age_output_loss: 1.3891 - val_emotion_output_accuracy: 0.4354 - val_emotion_output_loss: 1.4956 - val_ethnicity_output_accuracy: 0.2554 - val_ethnicity_output_loss: 2.3154 - val_gender_output_accuracy: 0.5155 - val_gender_output_loss: 0.8516 - val_loss: 1.5180 - learning_rate: 2.5000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - age_output_accuracy: 0.3474 - age_output_loss: 1.5404 - emotion_output_accuracy: 0.5196 - emotion_output_loss: 1.2684 - ethnicity_output_accuracy: 0.2137 - ethnicity_output_loss: 2.2212 - gender_output_accuracy: 0.4937 - gender_output_loss: 0.9204 - loss: 1.2684\n",
      "Epoch 28: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 304ms/step - age_output_accuracy: 0.3467 - age_output_loss: 1.5316 - emotion_output_accuracy: 0.5231 - emotion_output_loss: 1.2612 - ethnicity_output_accuracy: 0.2157 - ethnicity_output_loss: 2.2114 - gender_output_accuracy: 0.4951 - gender_output_loss: 0.9144 - loss: 1.2682 - val_age_output_accuracy: 0.4178 - val_age_output_loss: 1.3723 - val_emotion_output_accuracy: 0.4333 - val_emotion_output_loss: 1.5922 - val_ethnicity_output_accuracy: 0.2265 - val_ethnicity_output_loss: 1.7758 - val_gender_output_accuracy: 0.2566 - val_gender_output_loss: 1.1508 - val_loss: 1.6166 - learning_rate: 2.5000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - age_output_accuracy: 0.3431 - age_output_loss: 1.5382 - emotion_output_accuracy: 0.5398 - emotion_output_loss: 1.2376 - ethnicity_output_accuracy: 0.2099 - ethnicity_output_loss: 2.2125 - gender_output_accuracy: 0.4889 - gender_output_loss: 0.9093 - loss: 1.2376\n",
      "Epoch 29: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 292ms/step - age_output_accuracy: 0.3443 - age_output_loss: 1.5256 - emotion_output_accuracy: 0.5429 - emotion_output_loss: 1.2296 - ethnicity_output_accuracy: 0.2063 - ethnicity_output_loss: 2.2015 - gender_output_accuracy: 0.4966 - gender_output_loss: 0.9073 - loss: 1.2356 - val_age_output_accuracy: 0.2537 - val_age_output_loss: 1.6404 - val_emotion_output_accuracy: 0.4369 - val_emotion_output_loss: 1.4156 - val_ethnicity_output_accuracy: 0.2482 - val_ethnicity_output_loss: 1.6942 - val_gender_output_accuracy: 0.3606 - val_gender_output_loss: 0.9142 - val_loss: 1.4368 - learning_rate: 1.2500e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - age_output_accuracy: 0.3437 - age_output_loss: 1.5108 - emotion_output_accuracy: 0.5477 - emotion_output_loss: 1.2190 - ethnicity_output_accuracy: 0.2133 - ethnicity_output_loss: 2.1924 - gender_output_accuracy: 0.4912 - gender_output_loss: 0.9298 - loss: 1.2190\n",
      "Epoch 30: val_emotion_output_accuracy did not improve from 0.46070\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 272ms/step - age_output_accuracy: 0.3421 - age_output_loss: 1.5104 - emotion_output_accuracy: 0.5535 - emotion_output_loss: 1.2062 - ethnicity_output_accuracy: 0.2127 - ethnicity_output_loss: 2.1949 - gender_output_accuracy: 0.4899 - gender_output_loss: 0.9206 - loss: 1.2129 - val_age_output_accuracy: 0.3959 - val_age_output_loss: 1.3441 - val_emotion_output_accuracy: 0.4314 - val_emotion_output_loss: 1.5865 - val_ethnicity_output_accuracy: 0.1539 - val_ethnicity_output_loss: 1.9629 - val_gender_output_accuracy: 0.3202 - val_gender_output_loss: 1.0234 - val_loss: 1.6110 - learning_rate: 1.2500e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - age_output_accuracy: 0.3434 - age_output_loss: 1.4563 - emotion_output_accuracy: 0.5490 - emotion_output_loss: 1.2170 - ethnicity_output_accuracy: 0.2157 - ethnicity_output_loss: 2.2011 - gender_output_accuracy: 0.4896 - gender_output_loss: 0.9449 - loss: 1.2170\n",
      "Epoch 31: val_emotion_output_accuracy improved from 0.46070 to 0.49595, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 272ms/step - age_output_accuracy: 0.3458 - age_output_loss: 1.4529 - emotion_output_accuracy: 0.5554 - emotion_output_loss: 1.1985 - ethnicity_output_accuracy: 0.2149 - ethnicity_output_loss: 2.1812 - gender_output_accuracy: 0.4876 - gender_output_loss: 0.9283 - loss: 1.2051 - val_age_output_accuracy: 0.2677 - val_age_output_loss: 1.5082 - val_emotion_output_accuracy: 0.4960 - val_emotion_output_loss: 1.3513 - val_ethnicity_output_accuracy: 0.2139 - val_ethnicity_output_loss: 1.8791 - val_gender_output_accuracy: 0.3916 - val_gender_output_loss: 0.9196 - val_loss: 1.3716 - learning_rate: 1.2500e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - age_output_accuracy: 0.3366 - age_output_loss: 1.4967 - emotion_output_accuracy: 0.5458 - emotion_output_loss: 1.2057 - ethnicity_output_accuracy: 0.2171 - ethnicity_output_loss: 2.1986 - gender_output_accuracy: 0.4835 - gender_output_loss: 0.9326 - loss: 1.2057\n",
      "Epoch 32: val_emotion_output_accuracy did not improve from 0.49595\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 278ms/step - age_output_accuracy: 0.3467 - age_output_loss: 1.4976 - emotion_output_accuracy: 0.5487 - emotion_output_loss: 1.1972 - ethnicity_output_accuracy: 0.2191 - ethnicity_output_loss: 2.1864 - gender_output_accuracy: 0.4863 - gender_output_loss: 0.9328 - loss: 1.2031 - val_age_output_accuracy: 0.3111 - val_age_output_loss: 1.4142 - val_emotion_output_accuracy: 0.4821 - val_emotion_output_loss: 1.4029 - val_ethnicity_output_accuracy: 0.2368 - val_ethnicity_output_loss: 1.9741 - val_gender_output_accuracy: 0.5431 - val_gender_output_loss: 0.7642 - val_loss: 1.4237 - learning_rate: 1.2500e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - age_output_accuracy: 0.3400 - age_output_loss: 1.5396 - emotion_output_accuracy: 0.5686 - emotion_output_loss: 1.1774 - ethnicity_output_accuracy: 0.2141 - ethnicity_output_loss: 2.2061 - gender_output_accuracy: 0.4941 - gender_output_loss: 0.9089 - loss: 1.1774\n",
      "Epoch 33: val_emotion_output_accuracy improved from 0.49595 to 0.50357, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 282ms/step - age_output_accuracy: 0.3414 - age_output_loss: 1.4681 - emotion_output_accuracy: 0.5592 - emotion_output_loss: 1.1895 - ethnicity_output_accuracy: 0.2193 - ethnicity_output_loss: 2.1820 - gender_output_accuracy: 0.4922 - gender_output_loss: 0.9135 - loss: 1.1963 - val_age_output_accuracy: 0.2766 - val_age_output_loss: 1.5761 - val_emotion_output_accuracy: 0.5036 - val_emotion_output_loss: 1.3358 - val_ethnicity_output_accuracy: 0.2554 - val_ethnicity_output_loss: 1.8022 - val_gender_output_accuracy: 0.3776 - val_gender_output_loss: 0.9277 - val_loss: 1.3558 - learning_rate: 1.2500e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - age_output_accuracy: 0.3445 - age_output_loss: 1.4540 - emotion_output_accuracy: 0.5695 - emotion_output_loss: 1.1776 - ethnicity_output_accuracy: 0.2187 - ethnicity_output_loss: 2.1826 - gender_output_accuracy: 0.4760 - gender_output_loss: 0.9404 - loss: 1.1776\n",
      "Epoch 34: val_emotion_output_accuracy did not improve from 0.50357\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 366ms/step - age_output_accuracy: 0.3445 - age_output_loss: 1.4801 - emotion_output_accuracy: 0.5636 - emotion_output_loss: 1.1873 - ethnicity_output_accuracy: 0.2195 - ethnicity_output_loss: 2.1706 - gender_output_accuracy: 0.4882 - gender_output_loss: 0.9183 - loss: 1.1933 - val_age_output_accuracy: 0.3209 - val_age_output_loss: 1.3322 - val_emotion_output_accuracy: 0.4814 - val_emotion_output_loss: 1.3789 - val_ethnicity_output_accuracy: 0.2077 - val_ethnicity_output_loss: 1.9557 - val_gender_output_accuracy: 0.4543 - val_gender_output_loss: 0.8584 - val_loss: 1.3995 - learning_rate: 1.2500e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - age_output_accuracy: 0.3371 - age_output_loss: 1.5033 - emotion_output_accuracy: 0.5676 - emotion_output_loss: 1.1815 - ethnicity_output_accuracy: 0.2189 - ethnicity_output_loss: 2.2012 - gender_output_accuracy: 0.4967 - gender_output_loss: 0.9366 - loss: 1.1815\n",
      "Epoch 35: val_emotion_output_accuracy did not improve from 0.50357\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 304ms/step - age_output_accuracy: 0.3387 - age_output_loss: 1.4730 - emotion_output_accuracy: 0.5623 - emotion_output_loss: 1.1775 - ethnicity_output_accuracy: 0.2151 - ethnicity_output_loss: 2.1851 - gender_output_accuracy: 0.4966 - gender_output_loss: 0.9200 - loss: 1.1833 - val_age_output_accuracy: 0.1956 - val_age_output_loss: 1.7059 - val_emotion_output_accuracy: 0.5026 - val_emotion_output_loss: 1.3481 - val_ethnicity_output_accuracy: 0.2425 - val_ethnicity_output_loss: 1.7790 - val_gender_output_accuracy: 0.3647 - val_gender_output_loss: 0.8886 - val_loss: 1.3681 - learning_rate: 1.2500e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - age_output_accuracy: 0.3489 - age_output_loss: 1.5023 - emotion_output_accuracy: 0.5704 - emotion_output_loss: 1.1668 - ethnicity_output_accuracy: 0.2179 - ethnicity_output_loss: 2.1853 - gender_output_accuracy: 0.4924 - gender_output_loss: 0.9385 - loss: 1.1668\n",
      "Epoch 36: val_emotion_output_accuracy did not improve from 0.50357\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 343ms/step - age_output_accuracy: 0.3451 - age_output_loss: 1.5073 - emotion_output_accuracy: 0.5664 - emotion_output_loss: 1.1660 - ethnicity_output_accuracy: 0.2164 - ethnicity_output_loss: 2.1759 - gender_output_accuracy: 0.4953 - gender_output_loss: 0.9213 - loss: 1.1714 - val_age_output_accuracy: 0.2932 - val_age_output_loss: 1.5238 - val_emotion_output_accuracy: 0.4762 - val_emotion_output_loss: 1.4131 - val_ethnicity_output_accuracy: 0.3318 - val_ethnicity_output_loss: 1.6749 - val_gender_output_accuracy: 0.4505 - val_gender_output_loss: 0.8663 - val_loss: 1.4340 - learning_rate: 1.2500e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - age_output_accuracy: 0.3450 - age_output_loss: 1.5271 - emotion_output_accuracy: 0.5636 - emotion_output_loss: 1.1799 - ethnicity_output_accuracy: 0.2148 - ethnicity_output_loss: 2.1853 - gender_output_accuracy: 0.4966 - gender_output_loss: 0.9306 - loss: 1.1799\n",
      "Epoch 37: val_emotion_output_accuracy did not improve from 0.50357\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 552ms/step - age_output_accuracy: 0.3440 - age_output_loss: 1.5221 - emotion_output_accuracy: 0.5672 - emotion_output_loss: 1.1631 - ethnicity_output_accuracy: 0.2172 - ethnicity_output_loss: 2.1738 - gender_output_accuracy: 0.4908 - gender_output_loss: 0.9192 - loss: 1.1679 - val_age_output_accuracy: 0.3020 - val_age_output_loss: 1.4427 - val_emotion_output_accuracy: 0.4605 - val_emotion_output_loss: 1.4730 - val_ethnicity_output_accuracy: 0.1760 - val_ethnicity_output_loss: 1.8774 - val_gender_output_accuracy: 0.3611 - val_gender_output_loss: 0.9548 - val_loss: 1.4953 - learning_rate: 1.2500e-04\n",
      "Epoch 38/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - age_output_accuracy: 0.3379 - age_output_loss: 1.5445 - emotion_output_accuracy: 0.5691 - emotion_output_loss: 1.1510 - ethnicity_output_accuracy: 0.2065 - ethnicity_output_loss: 2.1958 - gender_output_accuracy: 0.4750 - gender_output_loss: 0.9466 - loss: 1.1510\n",
      "Epoch 38: val_emotion_output_accuracy did not improve from 0.50357\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 498ms/step - age_output_accuracy: 0.3443 - age_output_loss: 1.4732 - emotion_output_accuracy: 0.5745 - emotion_output_loss: 1.1448 - ethnicity_output_accuracy: 0.2129 - ethnicity_output_loss: 2.1742 - gender_output_accuracy: 0.4822 - gender_output_loss: 0.9230 - loss: 1.1505 - val_age_output_accuracy: 0.2382 - val_age_output_loss: 1.6492 - val_emotion_output_accuracy: 0.4788 - val_emotion_output_loss: 1.4025 - val_ethnicity_output_accuracy: 0.2561 - val_ethnicity_output_loss: 1.7486 - val_gender_output_accuracy: 0.3094 - val_gender_output_loss: 0.9725 - val_loss: 1.4233 - learning_rate: 6.2500e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - age_output_accuracy: 0.3449 - age_output_loss: 1.5553 - emotion_output_accuracy: 0.5776 - emotion_output_loss: 1.1462 - ethnicity_output_accuracy: 0.2131 - ethnicity_output_loss: 2.1846 - gender_output_accuracy: 0.4883 - gender_output_loss: 0.9352 - loss: 1.1461\n",
      "Epoch 39: val_emotion_output_accuracy improved from 0.50357 to 0.50524, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 792ms/step - age_output_accuracy: 0.3417 - age_output_loss: 1.5247 - emotion_output_accuracy: 0.5824 - emotion_output_loss: 1.1430 - ethnicity_output_accuracy: 0.2128 - ethnicity_output_loss: 2.1800 - gender_output_accuracy: 0.4909 - gender_output_loss: 0.9173 - loss: 1.1480 - val_age_output_accuracy: 0.2287 - val_age_output_loss: 1.6353 - val_emotion_output_accuracy: 0.5052 - val_emotion_output_loss: 1.3371 - val_ethnicity_output_accuracy: 0.3080 - val_ethnicity_output_loss: 1.6675 - val_gender_output_accuracy: 0.3659 - val_gender_output_loss: 0.9074 - val_loss: 1.3574 - learning_rate: 6.2500e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - age_output_accuracy: 0.3315 - age_output_loss: 1.5424 - emotion_output_accuracy: 0.5864 - emotion_output_loss: 1.1332 - ethnicity_output_accuracy: 0.2150 - ethnicity_output_loss: 2.1808 - gender_output_accuracy: 0.4860 - gender_output_loss: 0.9340 - loss: 1.1332\n",
      "Epoch 40: val_emotion_output_accuracy improved from 0.50524 to 0.51787, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 280ms/step - age_output_accuracy: 0.3354 - age_output_loss: 1.4969 - emotion_output_accuracy: 0.5831 - emotion_output_loss: 1.1343 - ethnicity_output_accuracy: 0.2160 - ethnicity_output_loss: 2.1895 - gender_output_accuracy: 0.4855 - gender_output_loss: 0.9289 - loss: 1.1400 - val_age_output_accuracy: 0.2725 - val_age_output_loss: 1.5224 - val_emotion_output_accuracy: 0.5179 - val_emotion_output_loss: 1.2948 - val_ethnicity_output_accuracy: 0.2454 - val_ethnicity_output_loss: 1.9052 - val_gender_output_accuracy: 0.4293 - val_gender_output_loss: 0.8748 - val_loss: 1.3141 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "history_A = cnn_model.fit(\n",
    "    train_ds, validation_data=val_ds,\n",
    "    epochs=EPOCHS_STAGE_A, callbacks=callbacks_A, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8b5dae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CNN  Stage B (very light multitask, emotion-dominant)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n CNN  Stage B (very light multitask, emotion-dominant)\")\n",
    "loss_w = {'emotion_output': 1.8, 'age_output': 0.05, 'ethnicity_output': 0.10}\n",
    "if USE_GENDER: loss_w['gender_output'] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42594acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "                  loss=losses, loss_weights=loss_w, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04712322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    198/Unknown \u001b[1m47s\u001b[0m 216ms/step - age_output_accuracy: 0.3589 - age_output_loss: 1.3116 - emotion_output_accuracy: 0.5610 - emotion_output_loss: 1.1905 - ethnicity_output_accuracy: 0.3587 - ethnicity_output_loss: 1.7180 - gender_output_accuracy: 0.5230 - gender_output_loss: 0.8185 - loss: 2.4212\n",
      "Epoch 1: val_emotion_output_accuracy improved from None to 0.47308, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 233ms/step - age_output_accuracy: 0.3729 - age_output_loss: 1.2310 - emotion_output_accuracy: 0.5702 - emotion_output_loss: 1.1614 - ethnicity_output_accuracy: 0.4551 - ethnicity_output_loss: 1.4801 - gender_output_accuracy: 0.5433 - gender_output_loss: 0.7571 - loss: 2.3503 - val_age_output_accuracy: 0.3328 - val_age_output_loss: 1.1751 - val_emotion_output_accuracy: 0.4731 - val_emotion_output_loss: 1.4990 - val_ethnicity_output_accuracy: 0.5319 - val_ethnicity_output_loss: 1.3211 - val_gender_output_accuracy: 0.7113 - val_gender_output_loss: 0.5700 - val_loss: 2.9603 - learning_rate: 2.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - age_output_accuracy: 0.3930 - age_output_loss: 1.1798 - emotion_output_accuracy: 0.5729 - emotion_output_loss: 1.1438 - ethnicity_output_accuracy: 0.6377 - ethnicity_output_loss: 1.1492 - gender_output_accuracy: 0.5872 - gender_output_loss: 0.6827 - loss: 2.2670\n",
      "Epoch 2: val_emotion_output_accuracy improved from 0.47308 to 0.48547, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 233ms/step - age_output_accuracy: 0.3933 - age_output_loss: 1.1466 - emotion_output_accuracy: 0.5723 - emotion_output_loss: 1.1521 - ethnicity_output_accuracy: 0.6603 - ethnicity_output_loss: 1.0985 - gender_output_accuracy: 0.5966 - gender_output_loss: 0.6801 - loss: 2.2861 - val_age_output_accuracy: 0.3173 - val_age_output_loss: 1.1595 - val_emotion_output_accuracy: 0.4855 - val_emotion_output_loss: 1.3898 - val_ethnicity_output_accuracy: 0.7399 - val_ethnicity_output_loss: 0.8987 - val_gender_output_accuracy: 0.7256 - val_gender_output_loss: 0.5465 - val_loss: 2.7162 - learning_rate: 2.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - age_output_accuracy: 0.3992 - age_output_loss: 1.1323 - emotion_output_accuracy: 0.5769 - emotion_output_loss: 1.1462 - ethnicity_output_accuracy: 0.7046 - ethnicity_output_loss: 1.0112 - gender_output_accuracy: 0.6147 - gender_output_loss: 0.6538 - loss: 2.2535\n",
      "Epoch 3: val_emotion_output_accuracy did not improve from 0.48547\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 256ms/step - age_output_accuracy: 0.4036 - age_output_loss: 1.1058 - emotion_output_accuracy: 0.5743 - emotion_output_loss: 1.1464 - ethnicity_output_accuracy: 0.7071 - ethnicity_output_loss: 0.9990 - gender_output_accuracy: 0.6185 - gender_output_loss: 0.6540 - loss: 2.2637 - val_age_output_accuracy: 0.3642 - val_age_output_loss: 1.1674 - val_emotion_output_accuracy: 0.4478 - val_emotion_output_loss: 1.4737 - val_ethnicity_output_accuracy: 0.7434 - val_ethnicity_output_loss: 0.8538 - val_gender_output_accuracy: 0.8185 - val_gender_output_loss: 0.4407 - val_loss: 2.8615 - learning_rate: 2.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - age_output_accuracy: 0.4092 - age_output_loss: 1.0756 - emotion_output_accuracy: 0.5716 - emotion_output_loss: 1.1550 - ethnicity_output_accuracy: 0.7226 - ethnicity_output_loss: 0.9604 - gender_output_accuracy: 0.6291 - gender_output_loss: 0.6366 - loss: 2.2606\n",
      "Epoch 4: val_emotion_output_accuracy did not improve from 0.48547\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1340s\u001b[0m 7s/step - age_output_accuracy: 0.4161 - age_output_loss: 1.0869 - emotion_output_accuracy: 0.5701 - emotion_output_loss: 1.1503 - ethnicity_output_accuracy: 0.7170 - ethnicity_output_loss: 0.9708 - gender_output_accuracy: 0.6359 - gender_output_loss: 0.6345 - loss: 2.2654 - val_age_output_accuracy: 0.3037 - val_age_output_loss: 1.1485 - val_emotion_output_accuracy: 0.4728 - val_emotion_output_loss: 1.4490 - val_ethnicity_output_accuracy: 0.7482 - val_ethnicity_output_loss: 0.8520 - val_gender_output_accuracy: 0.8101 - val_gender_output_loss: 0.4486 - val_loss: 2.8148 - learning_rate: 2.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - age_output_accuracy: 0.4207 - age_output_loss: 1.0827 - emotion_output_accuracy: 0.5917 - emotion_output_loss: 1.1216 - ethnicity_output_accuracy: 0.7241 - ethnicity_output_loss: 0.9516 - gender_output_accuracy: 0.6462 - gender_output_loss: 0.6255 - loss: 2.1995\n",
      "Epoch 5: val_emotion_output_accuracy improved from 0.48547 to 0.50548, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 181ms/step - age_output_accuracy: 0.4163 - age_output_loss: 1.0515 - emotion_output_accuracy: 0.5929 - emotion_output_loss: 1.1129 - ethnicity_output_accuracy: 0.7208 - ethnicity_output_loss: 0.9478 - gender_output_accuracy: 0.6486 - gender_output_loss: 0.6227 - loss: 2.1925 - val_age_output_accuracy: 0.4533 - val_age_output_loss: 0.9673 - val_emotion_output_accuracy: 0.5055 - val_emotion_output_loss: 1.3264 - val_ethnicity_output_accuracy: 0.7451 - val_ethnicity_output_loss: 0.8461 - val_gender_output_accuracy: 0.7613 - val_gender_output_loss: 0.5167 - val_loss: 2.5855 - learning_rate: 2.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - age_output_accuracy: 0.4179 - age_output_loss: 1.0739 - emotion_output_accuracy: 0.5847 - emotion_output_loss: 1.1231 - ethnicity_output_accuracy: 0.7288 - ethnicity_output_loss: 0.9238 - gender_output_accuracy: 0.6506 - gender_output_loss: 0.6236 - loss: 2.1989\n",
      "Epoch 6: val_emotion_output_accuracy did not improve from 0.50548\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 182ms/step - age_output_accuracy: 0.4233 - age_output_loss: 1.0530 - emotion_output_accuracy: 0.5869 - emotion_output_loss: 1.1232 - ethnicity_output_accuracy: 0.7253 - ethnicity_output_loss: 0.9247 - gender_output_accuracy: 0.6581 - gender_output_loss: 0.6098 - loss: 2.2060 - val_age_output_accuracy: 0.3404 - val_age_output_loss: 1.1001 - val_emotion_output_accuracy: 0.4302 - val_emotion_output_loss: 1.6781 - val_ethnicity_output_accuracy: 0.7520 - val_ethnicity_output_loss: 0.8399 - val_gender_output_accuracy: 0.8240 - val_gender_output_loss: 0.3936 - val_loss: 3.2254 - learning_rate: 2.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - age_output_accuracy: 0.4296 - age_output_loss: 1.0103 - emotion_output_accuracy: 0.5735 - emotion_output_loss: 1.1392 - ethnicity_output_accuracy: 0.7309 - ethnicity_output_loss: 0.9256 - gender_output_accuracy: 0.6705 - gender_output_loss: 0.5922 - loss: 2.2232\n",
      "Epoch 7: val_emotion_output_accuracy did not improve from 0.50548\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 181ms/step - age_output_accuracy: 0.4273 - age_output_loss: 1.0172 - emotion_output_accuracy: 0.5854 - emotion_output_loss: 1.1192 - ethnicity_output_accuracy: 0.7281 - ethnicity_output_loss: 0.9267 - gender_output_accuracy: 0.6693 - gender_output_loss: 0.5975 - loss: 2.1987 - val_age_output_accuracy: 0.4574 - val_age_output_loss: 0.9860 - val_emotion_output_accuracy: 0.4881 - val_emotion_output_loss: 1.3273 - val_ethnicity_output_accuracy: 0.7458 - val_ethnicity_output_loss: 0.8412 - val_gender_output_accuracy: 0.8051 - val_gender_output_loss: 0.4460 - val_loss: 2.5829 - learning_rate: 2.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - age_output_accuracy: 0.4351 - age_output_loss: 1.0313 - emotion_output_accuracy: 0.5965 - emotion_output_loss: 1.1008 - ethnicity_output_accuracy: 0.7359 - ethnicity_output_loss: 0.9048 - gender_output_accuracy: 0.6747 - gender_output_loss: 0.5901 - loss: 2.1530\n",
      "Epoch 8: val_emotion_output_accuracy did not improve from 0.50548\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 183ms/step - age_output_accuracy: 0.4309 - age_output_loss: 1.0297 - emotion_output_accuracy: 0.5982 - emotion_output_loss: 1.0980 - ethnicity_output_accuracy: 0.7326 - ethnicity_output_loss: 0.9136 - gender_output_accuracy: 0.6805 - gender_output_loss: 0.5918 - loss: 2.1581 - val_age_output_accuracy: 0.4886 - val_age_output_loss: 0.9340 - val_emotion_output_accuracy: 0.4931 - val_emotion_output_loss: 1.3766 - val_ethnicity_output_accuracy: 0.7461 - val_ethnicity_output_loss: 0.8462 - val_gender_output_accuracy: 0.8056 - val_gender_output_loss: 0.4435 - val_loss: 2.6718 - learning_rate: 2.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - age_output_accuracy: 0.4334 - age_output_loss: 1.0344 - emotion_output_accuracy: 0.5889 - emotion_output_loss: 1.0983 - ethnicity_output_accuracy: 0.7393 - ethnicity_output_loss: 0.9018 - gender_output_accuracy: 0.6830 - gender_output_loss: 0.5821 - loss: 2.1479\n",
      "Epoch 9: val_emotion_output_accuracy improved from 0.50548 to 0.52501, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 234ms/step - age_output_accuracy: 0.4347 - age_output_loss: 1.0122 - emotion_output_accuracy: 0.5974 - emotion_output_loss: 1.0903 - ethnicity_output_accuracy: 0.7324 - ethnicity_output_loss: 0.9080 - gender_output_accuracy: 0.6852 - gender_output_loss: 0.5835 - loss: 2.1427 - val_age_output_accuracy: 0.4278 - val_age_output_loss: 1.0127 - val_emotion_output_accuracy: 0.5250 - val_emotion_output_loss: 1.3279 - val_ethnicity_output_accuracy: 0.7468 - val_ethnicity_output_loss: 0.8357 - val_gender_output_accuracy: 0.8242 - val_gender_output_loss: 0.3977 - val_loss: 2.5828 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - age_output_accuracy: 0.4371 - age_output_loss: 0.9653 - emotion_output_accuracy: 0.5915 - emotion_output_loss: 1.1097 - ethnicity_output_accuracy: 0.7255 - ethnicity_output_loss: 0.9195 - gender_output_accuracy: 0.6845 - gender_output_loss: 0.5804 - loss: 2.1666\n",
      "Epoch 10: val_emotion_output_accuracy did not improve from 0.52501\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 307ms/step - age_output_accuracy: 0.4463 - age_output_loss: 0.9903 - emotion_output_accuracy: 0.5975 - emotion_output_loss: 1.0956 - ethnicity_output_accuracy: 0.7304 - ethnicity_output_loss: 0.9067 - gender_output_accuracy: 0.6881 - gender_output_loss: 0.5765 - loss: 2.1514 - val_age_output_accuracy: 0.3797 - val_age_output_loss: 1.0108 - val_emotion_output_accuracy: 0.4976 - val_emotion_output_loss: 1.3272 - val_ethnicity_output_accuracy: 0.7513 - val_ethnicity_output_loss: 0.8265 - val_gender_output_accuracy: 0.8242 - val_gender_output_loss: 0.3887 - val_loss: 2.5791 - learning_rate: 2.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - age_output_accuracy: 0.4555 - age_output_loss: 0.9952 - emotion_output_accuracy: 0.6001 - emotion_output_loss: 1.0865 - ethnicity_output_accuracy: 0.7319 - ethnicity_output_loss: 0.8995 - gender_output_accuracy: 0.6836 - gender_output_loss: 0.5944 - loss: 2.1250\n",
      "Epoch 11: val_emotion_output_accuracy did not improve from 0.52501\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 252ms/step - age_output_accuracy: 0.4532 - age_output_loss: 0.9819 - emotion_output_accuracy: 0.5976 - emotion_output_loss: 1.0926 - ethnicity_output_accuracy: 0.7359 - ethnicity_output_loss: 0.8923 - gender_output_accuracy: 0.6809 - gender_output_loss: 0.5840 - loss: 2.1418 - val_age_output_accuracy: 0.3818 - val_age_output_loss: 1.0272 - val_emotion_output_accuracy: 0.4764 - val_emotion_output_loss: 1.4334 - val_ethnicity_output_accuracy: 0.7430 - val_ethnicity_output_loss: 0.8438 - val_gender_output_accuracy: 0.8275 - val_gender_output_loss: 0.4038 - val_loss: 2.7755 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - age_output_accuracy: 0.4528 - age_output_loss: 0.9915 - emotion_output_accuracy: 0.6070 - emotion_output_loss: 1.0734 - ethnicity_output_accuracy: 0.7389 - ethnicity_output_loss: 0.8939 - gender_output_accuracy: 0.7003 - gender_output_loss: 0.5818 - loss: 2.1001\n",
      "Epoch 12: val_emotion_output_accuracy did not improve from 0.52501\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 244ms/step - age_output_accuracy: 0.4495 - age_output_loss: 0.9934 - emotion_output_accuracy: 0.6089 - emotion_output_loss: 1.0703 - ethnicity_output_accuracy: 0.7357 - ethnicity_output_loss: 0.8893 - gender_output_accuracy: 0.6975 - gender_output_loss: 0.5712 - loss: 2.1035 - val_age_output_accuracy: 0.3659 - val_age_output_loss: 1.1521 - val_emotion_output_accuracy: 0.4667 - val_emotion_output_loss: 1.6155 - val_ethnicity_output_accuracy: 0.7485 - val_ethnicity_output_loss: 0.8411 - val_gender_output_accuracy: 0.8035 - val_gender_output_loss: 0.4318 - val_loss: 3.1154 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - age_output_accuracy: 0.4534 - age_output_loss: 0.9498 - emotion_output_accuracy: 0.6031 - emotion_output_loss: 1.0753 - ethnicity_output_accuracy: 0.7364 - ethnicity_output_loss: 0.8915 - gender_output_accuracy: 0.6964 - gender_output_loss: 0.5693 - loss: 2.1007\n",
      "Epoch 13: val_emotion_output_accuracy did not improve from 0.52501\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 233ms/step - age_output_accuracy: 0.4499 - age_output_loss: 0.9867 - emotion_output_accuracy: 0.6067 - emotion_output_loss: 1.0699 - ethnicity_output_accuracy: 0.7378 - ethnicity_output_loss: 0.8873 - gender_output_accuracy: 0.6955 - gender_output_loss: 0.5655 - loss: 2.1031 - val_age_output_accuracy: 0.4285 - val_age_output_loss: 1.0483 - val_emotion_output_accuracy: 0.4969 - val_emotion_output_loss: 1.4308 - val_ethnicity_output_accuracy: 0.7473 - val_ethnicity_output_loss: 0.8338 - val_gender_output_accuracy: 0.8175 - val_gender_output_loss: 0.4084 - val_loss: 2.7735 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - age_output_accuracy: 0.4396 - age_output_loss: 0.9683 - emotion_output_accuracy: 0.6163 - emotion_output_loss: 1.0530 - ethnicity_output_accuracy: 0.7407 - ethnicity_output_loss: 0.8796 - gender_output_accuracy: 0.6907 - gender_output_loss: 0.5732 - loss: 2.0604\n",
      "Epoch 14: val_emotion_output_accuracy did not improve from 0.52501\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 276ms/step - age_output_accuracy: 0.4500 - age_output_loss: 0.9636 - emotion_output_accuracy: 0.6192 - emotion_output_loss: 1.0442 - ethnicity_output_accuracy: 0.7383 - ethnicity_output_loss: 0.8799 - gender_output_accuracy: 0.6992 - gender_output_loss: 0.5613 - loss: 2.0550 - val_age_output_accuracy: 0.4421 - val_age_output_loss: 0.9755 - val_emotion_output_accuracy: 0.5191 - val_emotion_output_loss: 1.2926 - val_ethnicity_output_accuracy: 0.7508 - val_ethnicity_output_loss: 0.8310 - val_gender_output_accuracy: 0.8306 - val_gender_output_loss: 0.4034 - val_loss: 2.5160 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - age_output_accuracy: 0.4523 - age_output_loss: 0.9421 - emotion_output_accuracy: 0.6205 - emotion_output_loss: 1.0338 - ethnicity_output_accuracy: 0.7372 - ethnicity_output_loss: 0.8803 - gender_output_accuracy: 0.7141 - gender_output_loss: 0.5591 - loss: 2.0239\n",
      "Epoch 15: val_emotion_output_accuracy improved from 0.52501 to 0.52525, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 249ms/step - age_output_accuracy: 0.4521 - age_output_loss: 0.9554 - emotion_output_accuracy: 0.6214 - emotion_output_loss: 1.0239 - ethnicity_output_accuracy: 0.7385 - ethnicity_output_loss: 0.8775 - gender_output_accuracy: 0.7027 - gender_output_loss: 0.5585 - loss: 2.0162 - val_age_output_accuracy: 0.3857 - val_age_output_loss: 1.0173 - val_emotion_output_accuracy: 0.5253 - val_emotion_output_loss: 1.3214 - val_ethnicity_output_accuracy: 0.7513 - val_ethnicity_output_loss: 0.8249 - val_gender_output_accuracy: 0.8237 - val_gender_output_loss: 0.3987 - val_loss: 2.5679 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - age_output_accuracy: 0.4599 - age_output_loss: 0.9438 - emotion_output_accuracy: 0.6240 - emotion_output_loss: 1.0289 - ethnicity_output_accuracy: 0.7428 - ethnicity_output_loss: 0.8770 - gender_output_accuracy: 0.7114 - gender_output_loss: 0.5560 - loss: 2.0146\n",
      "Epoch 16: val_emotion_output_accuracy improved from 0.52525 to 0.53668, saving model to masked_face_multitask_model.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 294ms/step - age_output_accuracy: 0.4530 - age_output_loss: 0.9469 - emotion_output_accuracy: 0.6229 - emotion_output_loss: 1.0232 - ethnicity_output_accuracy: 0.7426 - ethnicity_output_loss: 0.8726 - gender_output_accuracy: 0.7087 - gender_output_loss: 0.5527 - loss: 2.0156 - val_age_output_accuracy: 0.4869 - val_age_output_loss: 0.9234 - val_emotion_output_accuracy: 0.5367 - val_emotion_output_loss: 1.2632 - val_ethnicity_output_accuracy: 0.7492 - val_ethnicity_output_loss: 0.8282 - val_gender_output_accuracy: 0.8147 - val_gender_output_loss: 0.4103 - val_loss: 2.4602 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - age_output_accuracy: 0.4500 - age_output_loss: 0.9555 - emotion_output_accuracy: 0.6283 - emotion_output_loss: 1.0277 - ethnicity_output_accuracy: 0.7485 - ethnicity_output_loss: 0.8552 - gender_output_accuracy: 0.7032 - gender_output_loss: 0.5524 - loss: 2.0108\n",
      "Epoch 17: val_emotion_output_accuracy did not improve from 0.53668\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 261ms/step - age_output_accuracy: 0.4575 - age_output_loss: 0.9531 - emotion_output_accuracy: 0.6260 - emotion_output_loss: 1.0198 - ethnicity_output_accuracy: 0.7408 - ethnicity_output_loss: 0.8712 - gender_output_accuracy: 0.7034 - gender_output_loss: 0.5494 - loss: 2.0055 - val_age_output_accuracy: 0.3854 - val_age_output_loss: 1.0342 - val_emotion_output_accuracy: 0.5157 - val_emotion_output_loss: 1.3690 - val_ethnicity_output_accuracy: 0.7554 - val_ethnicity_output_loss: 0.8271 - val_gender_output_accuracy: 0.8299 - val_gender_output_loss: 0.3732 - val_loss: 2.6552 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - age_output_accuracy: 0.4537 - age_output_loss: 0.9226 - emotion_output_accuracy: 0.6273 - emotion_output_loss: 1.0243 - ethnicity_output_accuracy: 0.7416 - ethnicity_output_loss: 0.8750 - gender_output_accuracy: 0.7078 - gender_output_loss: 0.5508 - loss: 2.0049\n",
      "Epoch 18: val_emotion_output_accuracy did not improve from 0.53668\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 266ms/step - age_output_accuracy: 0.4514 - age_output_loss: 0.9436 - emotion_output_accuracy: 0.6317 - emotion_output_loss: 1.0066 - ethnicity_output_accuracy: 0.7425 - ethnicity_output_loss: 0.8706 - gender_output_accuracy: 0.7080 - gender_output_loss: 0.5542 - loss: 1.9844 - val_age_output_accuracy: 0.3957 - val_age_output_loss: 1.0153 - val_emotion_output_accuracy: 0.5238 - val_emotion_output_loss: 1.3159 - val_ethnicity_output_accuracy: 0.7508 - val_ethnicity_output_loss: 0.8227 - val_gender_output_accuracy: 0.8337 - val_gender_output_loss: 0.3804 - val_loss: 2.5577 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - age_output_accuracy: 0.4599 - age_output_loss: 0.9183 - emotion_output_accuracy: 0.6358 - emotion_output_loss: 0.9988 - ethnicity_output_accuracy: 0.7458 - ethnicity_output_loss: 0.8607 - gender_output_accuracy: 0.7075 - gender_output_loss: 0.5642 - loss: 1.9581\n",
      "Epoch 19: val_emotion_output_accuracy did not improve from 0.53668\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 239ms/step - age_output_accuracy: 0.4565 - age_output_loss: 0.9444 - emotion_output_accuracy: 0.6335 - emotion_output_loss: 0.9983 - ethnicity_output_accuracy: 0.7418 - ethnicity_output_loss: 0.8654 - gender_output_accuracy: 0.7104 - gender_output_loss: 0.5526 - loss: 1.9700 - val_age_output_accuracy: 0.4578 - val_age_output_loss: 0.9507 - val_emotion_output_accuracy: 0.5293 - val_emotion_output_loss: 1.2833 - val_ethnicity_output_accuracy: 0.7520 - val_ethnicity_output_loss: 0.8205 - val_gender_output_accuracy: 0.8321 - val_gender_output_loss: 0.3884 - val_loss: 2.4958 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - age_output_accuracy: 0.4570 - age_output_loss: 0.9487 - emotion_output_accuracy: 0.6372 - emotion_output_loss: 1.0046 - ethnicity_output_accuracy: 0.7419 - ethnicity_output_loss: 0.8774 - gender_output_accuracy: 0.7123 - gender_output_loss: 0.5500 - loss: 1.9710\n",
      "Epoch 20: val_emotion_output_accuracy did not improve from 0.53668\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 217ms/step - age_output_accuracy: 0.4505 - age_output_loss: 0.9607 - emotion_output_accuracy: 0.6382 - emotion_output_loss: 0.9999 - ethnicity_output_accuracy: 0.7452 - ethnicity_output_loss: 0.8655 - gender_output_accuracy: 0.7105 - gender_output_loss: 0.5526 - loss: 1.9724 - val_age_output_accuracy: 0.4659 - val_age_output_loss: 0.9684 - val_emotion_output_accuracy: 0.5095 - val_emotion_output_loss: 1.3372 - val_ethnicity_output_accuracy: 0.7508 - val_ethnicity_output_loss: 0.8218 - val_gender_output_accuracy: 0.8156 - val_gender_output_loss: 0.4130 - val_loss: 2.5961 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "source": [
    "history_B = cnn_model.fit(\n",
    "    train_ds, validation_data=val_ds,\n",
    "    epochs=EPOCHS_FULL - EPOCHS_STAGE_A,  # 20\n",
    "    callbacks=callbacks_B, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe0744b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"masked_face_multitask_model_last.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1258e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MobileNetV2  emotion training\n",
      "Epoch 1/60\n",
      "    198/Unknown \u001b[1m37s\u001b[0m 162ms/step - accuracy: 0.2186 - loss: 1.9586\n",
      "Epoch 1: val_accuracy improved from None to 0.28633, saving model to mbv2_best.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 216ms/step - accuracy: 0.2512 - loss: 1.8552 - val_accuracy: 0.2863 - val_loss: 1.8309 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.3165 - loss: 1.7267\n",
      "Epoch 2: val_accuracy did not improve from 0.28633\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 180ms/step - accuracy: 0.3373 - loss: 1.6889 - val_accuracy: 0.2549 - val_loss: 1.9387 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.3852 - loss: 1.5890\n",
      "Epoch 3: val_accuracy improved from 0.28633 to 0.29967, saving model to mbv2_best.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 184ms/step - accuracy: 0.3966 - loss: 1.5580 - val_accuracy: 0.2997 - val_loss: 1.8517 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.4514 - loss: 1.4414\n",
      "Epoch 4: val_accuracy improved from 0.29967 to 0.31182, saving model to mbv2_best.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 168ms/step - accuracy: 0.4546 - loss: 1.4296 - val_accuracy: 0.3118 - val_loss: 1.9255 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5067 - loss: 1.3298\n",
      "Epoch 5: val_accuracy improved from 0.31182 to 0.35517, saving model to mbv2_best.keras\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 177ms/step - accuracy: 0.5149 - loss: 1.3057 - val_accuracy: 0.3552 - val_loss: 1.7772 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5342 - loss: 1.2368\n",
      "Epoch 6: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 169ms/step - accuracy: 0.5496 - loss: 1.2112 - val_accuracy: 0.3321 - val_loss: 1.9593 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.6126 - loss: 1.0920\n",
      "Epoch 7: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 185ms/step - accuracy: 0.6059 - loss: 1.0906 - val_accuracy: 0.3280 - val_loss: 1.9542 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6310 - loss: 1.0220\n",
      "Epoch 8: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 165ms/step - accuracy: 0.6377 - loss: 1.0139 - val_accuracy: 0.3430 - val_loss: 1.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6599 - loss: 0.9436\n",
      "Epoch 9: val_accuracy did not improve from 0.35517\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 192ms/step - accuracy: 0.6675 - loss: 0.9348 - val_accuracy: 0.3352 - val_loss: 2.1684 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7164 - loss: 0.8153\n",
      "Epoch 10: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 183ms/step - accuracy: 0.7231 - loss: 0.7900 - val_accuracy: 0.3349 - val_loss: 2.2048 - learning_rate: 5.0000e-05\n",
      "Epoch 11/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7415 - loss: 0.7397\n",
      "Epoch 11: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 172ms/step - accuracy: 0.7416 - loss: 0.7421 - val_accuracy: 0.3271 - val_loss: 2.4084 - learning_rate: 5.0000e-05\n",
      "Epoch 12/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7590 - loss: 0.6990\n",
      "Epoch 12: val_accuracy did not improve from 0.35517\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 190ms/step - accuracy: 0.7583 - loss: 0.7042 - val_accuracy: 0.3135 - val_loss: 2.4163 - learning_rate: 5.0000e-05\n",
      "Epoch 13/60\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7706 - loss: 0.6588\n",
      "Epoch 13: val_accuracy did not improve from 0.35517\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 182ms/step - accuracy: 0.7699 - loss: 0.6651 - val_accuracy: 0.3261 - val_loss: 2.4903 - learning_rate: 5.0000e-05\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "mb_model = None\n",
    "if USE_MBV2:\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "    def make_mbv2_ds(X, yE_int, batch=BATCH_SIZE_MBV2, shuffle=False):\n",
    "        n = len(X)\n",
    "        def gen():\n",
    "            for i in range(n):\n",
    "                yield np.asarray(X[i], dtype=np.float32), np.int32(yE_int[i])\n",
    "\n",
    "        sig_x = tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 1), dtype=tf.float32)\n",
    "        sig_y = tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        ds = tf.data.Dataset.from_generator(gen, output_signature=(sig_x, sig_y))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(buffer_size=min(n, 4096), seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "        def prep(x, y):\n",
    "            x = tf.image.grayscale_to_rgb(x)\n",
    "            x = tf.image.resize(x, [MBV2_SIZE, MBV2_SIZE])\n",
    "            x = x * 255.0\n",
    "            x = preprocess_input(x)\n",
    "            return x, y\n",
    "\n",
    "        ds = ds.map(prep, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    def build_mbv2_model(n_emotions, unfreeze_from=MBV2_UNFREEZE_FROM, input_size=MBV2_SIZE):\n",
    "        base = MobileNetV2(include_top=False, input_shape=(input_size, input_size, 3), weights='imagenet')\n",
    "        for lyr in base.layers:\n",
    "            lyr.trainable = False\n",
    "        if isinstance(unfreeze_from, int) and unfreeze_from < 0:\n",
    "            for lyr in base.layers[unfreeze_from:]:\n",
    "                if not isinstance(lyr, tf.keras.layers.BatchNormalization):\n",
    "                    lyr.trainable = True\n",
    "\n",
    "        inp = Input(shape=(input_size, input_size, 3), name=\"mbv2_input\")\n",
    "        aug = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "            tf.keras.layers.RandomRotation(0.04),\n",
    "            tf.keras.layers.RandomZoom(0.10),\n",
    "            tf.keras.layers.RandomContrast(0.10),\n",
    "        ])(inp)\n",
    "        x = base(aug, training=False)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.30)(x)\n",
    "        out = Dense(n_emotions, activation='softmax', name='emotion_output')(x)\n",
    "        return Model(inputs=inp, outputs=out, name=\"MobileNetV2_Emotion\")\n",
    "\n",
    "    train_ds_mbv2 = make_mbv2_ds(X_tr,  yE_tr_int,  shuffle=True)\n",
    "    val_ds_mbv2   = make_mbv2_ds(X_val, yE_val_int)\n",
    "    test_ds_mbv2  = make_mbv2_ds(X_te,  yE_te_int)\n",
    "\n",
    "    mb_model = build_mbv2_model(len(EMOS))\n",
    "    mb_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                     loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    emo_classes = np.arange(len(EMOS))\n",
    "    emo_weights = compute_class_weight('balanced', classes=emo_classes, y=yE_tr_int)\n",
    "    emo_weights = {int(c): float(w) for c, w in zip(emo_classes, emo_weights)}\n",
    "\n",
    "    mb_callbacks = [\n",
    "        ModelCheckpoint(\"mbv2_best.keras\", monitor='val_accuracy', mode='max', save_best_only=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.5, patience=4, min_lr=1e-6, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='max', patience=8, restore_best_weights=True, verbose=1, min_delta=1e-3),\n",
    "        CSVLogger(\"mbv2_training_log.csv\", append=False)\n",
    "    ]\n",
    "\n",
    "    print(\"\\n MobileNetV2  emotion training\")\n",
    "    mb_history = mb_model.fit(train_ds_mbv2, validation_data=val_ds_mbv2,\n",
    "                              class_weight=emo_weights,\n",
    "                              epochs=EPOCHS_FULL, callbacks=mb_callbacks, verbose=1)\n",
    "    mb_model.save(\"mbv2_last.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2bfeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sidecar = {\n",
    "    \"emotion\":        EMOS,\n",
    "    \"age\":            [\"024\",\"2539\",\"40+\"],\n",
    "    \"ethnicity\":      list(eth_le.classes_),\n",
    "    \"gender\":         [\"Male\",\"Female\"]\n",
    "}\n",
    "with open(\"masked_face_multitask_model.keras.labels.json\",\"w\") as f: json.dump(sidecar, f, indent=2)\n",
    "with open(\"masked_face_multitask_model_last.keras.labels.json\",\"w\") as f: json.dump(sidecar, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98372952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CNN Final Test Metrics:\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - age_output_accuracy: 0.4795 - age_output_loss: 0.9222 - emotion_output_accuracy: 0.5520 - emotion_output_loss: 1.2458 - ethnicity_output_accuracy: 0.7773 - ethnicity_output_loss: 0.7782 - gender_output_accuracy: 0.8195 - gender_output_loss: 0.4103 - loss: 2.4315\n",
      "loss: 2.4315\n",
      "compile_metrics: 1.2458\n",
      "emotion_output_loss: 0.9222\n",
      "age_output_loss: 0.7782\n",
      "ethnicity_output_loss: 0.4103\n",
      "gender_output_loss: 0.4795\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n CNN Final Test Metrics:\")\n",
    "results = cnn_model.evaluate(test_ds, verbose=1)\n",
    "for name, val in zip(cnn_model.metrics_names, results):\n",
    "    print(f\"{name}: {float(val):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5aeffe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PREDICT (head-specific, x-only) ----------\n",
    "x_only_test = test_ds.map(lambda x, *rest: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95281023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Ensure cnn_model is loaded ---\n",
    "try:\n",
    "    _ = cnn_model.input  # check if model exists\n",
    "except Exception:\n",
    "    cnn_model = tf.keras.models.load_model(\"masked_face_multitask_model.keras\", compile=False)\n",
    "\n",
    "# --- Create separate heads ---\n",
    "emotion_head   = tf.keras.Model(cnn_model.input, cnn_model.get_layer('emotion_output').output)\n",
    "age_head       = tf.keras.Model(cnn_model.input, cnn_model.get_layer('age_output').output)\n",
    "ethnicity_head = tf.keras.Model(cnn_model.input, cnn_model.get_layer('ethnicity_output').output)\n",
    "gender_head    = (\n",
    "    tf.keras.Model(cnn_model.input, cnn_model.get_layer('gender_output').output)\n",
    "    if USE_GENDER else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02a6c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_logits   = emotion_head.predict(x_only_test, verbose=0)\n",
    "age_logits       = age_head.predict(x_only_test, verbose=0)\n",
    "ethnicity_logits = ethnicity_head.predict(x_only_test, verbose=0)\n",
    "gender_logits    = gender_head.predict(x_only_test, verbose=0) if gender_head is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94bd6d5b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit shapes: emotion (4167, 7) age (4167, 3) ethnicity (4167, 5) gender (4167, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"logit shapes:\",\n",
    "      \"emotion\",   getattr(emotion_logits,   \"shape\", None),\n",
    "      \"age\",       getattr(age_logits,       \"shape\", None),\n",
    "      \"ethnicity\", getattr(ethnicity_logits, \"shape\", None),\n",
    "      \"gender\",    getattr(gender_logits,    \"shape\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7729e8f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Reports  CNN (Emotion/Age/Ethnicity[/Gender])\n",
    "# =========================================================\n",
    "def save_cm(yt, yp, labels, title_prefix, out_prefix, normalize=None):\n",
    "    cm = confusion_matrix(yt, yp, labels=list(range(len(labels))), normalize=normalize)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels, vmin=0 if normalize else None, vmax=1 if normalize else None)\n",
    "    title = f\"{title_prefix}  Confusion Matrix\" + (\" (Normalized)\" if normalize else \" (Counts)\")\n",
    "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    suffix = \"normalized\" if normalize else \"counts\"\n",
    "    plt.savefig(os.path.join(\"figures\", f\"{out_prefix}_cm_{suffix}.png\"), dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d59a1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion\n",
    "y_true_emotion = yE_te_int\n",
    "y_pred_emotion = np.argmax(emotion_logits, axis=1)\n",
    "save_cm(y_true_emotion, y_pred_emotion, EMOS, \"Emotion (CNN)\", \"emotion\", normalize=None)\n",
    "save_cm(y_true_emotion, y_pred_emotion, EMOS, \"Emotion (CNN)\", \"emotion\", normalize='true')\n",
    "with open(os.path.join(\"reports\", \"emotion_classification_report.txt\"), \"w\") as f:\n",
    "    f.write(classification_report(y_true_emotion, y_pred_emotion, target_names=EMOS, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec6b992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "y_true_age = np.argmax(yA_te, axis=1)\n",
    "y_pred_age = np.argmax(age_logits, axis=1)\n",
    "age_labels = [\"0-24\",\"25-39\",\"40+\"]\n",
    "save_cm(y_true_age, y_pred_age, age_labels, \"Age (CNN)\", \"age\", normalize=None)\n",
    "save_cm(y_true_age, y_pred_age, age_labels, \"Age (CNN)\", \"age\", normalize='true')\n",
    "with open(os.path.join(\"reports\", \"age_classification_report.txt\"), \"w\") as f:\n",
    "    f.write(classification_report(y_true_age, y_pred_age, target_names=age_labels, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1d5a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicity\n",
    "y_true_eth = np.argmax(yT_te, axis=1)\n",
    "y_pred_eth = np.argmax(ethnicity_logits, axis=1)\n",
    "eth_labels = list(eth_le.classes_)\n",
    "save_cm(y_true_eth, y_pred_eth, eth_labels, \"Ethnicity (CNN)\", \"ethnicity\", normalize=None)\n",
    "save_cm(y_true_eth, y_pred_eth, eth_labels, \"Ethnicity (CNN)\", \"ethnicity\", normalize='true')\n",
    "with open(os.path.join(\"reports\", \"ethnicity_classification_report.txt\"), \"w\") as f:\n",
    "    f.write(classification_report(y_true_eth, y_pred_eth, target_names=eth_labels, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26ecbb83",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "if USE_GENDER and (gender_logits is not None):\n",
    "    y_true_gender = yG_te.astype(int)\n",
    "    y_pred_gender = (gender_logits.ravel() >= 0.5).astype(int)\n",
    "    save_cm(y_true_gender, y_pred_gender, [\"male\",\"female\"], \"Gender (CNN)\", \"gender\", normalize=None)\n",
    "    save_cm(y_true_gender, y_pred_gender, [\"male\",\"female\"], \"Gender (CNN)\", \"gender\", normalize='true')\n",
    "    with open(os.path.join(\"reports\", \"gender_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(classification_report(y_true_gender, y_pred_gender, target_names=[\"male\",\"female\"], digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2057847",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Training curves\n",
    "# =========================================================\n",
    "def _merge_hist(hA, hB):\n",
    "    hist = {}\n",
    "    for k, v in hA.history.items():\n",
    "        hist[k] = list(v) + list(hB.history.get(k, []))\n",
    "    for k, v in hB.history.items():\n",
    "        if k not in hist: hist[k] = list(v)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e14d9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = _merge_hist(history_A, history_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "828229d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if isinstance(history, dict) and len(history) > 0:\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for key in ['emotion_output_accuracy','age_output_accuracy','ethnicity_output_accuracy'] + (['gender_output_accuracy'] if USE_GENDER else []):\n",
    "        if key in history:\n",
    "            plt.plot(history[key], label=f\"{key.replace('_accuracy','')} Train\")\n",
    "            vkey = f\"val_{key}\"\n",
    "            if vkey in history:\n",
    "                plt.plot(history[vkey], label=f\"{key.replace('_accuracy','')} Val\", linestyle=\"--\")\n",
    "    plt.title(f\"CNN Accuracy ({len(EMOS)}-class emotion)\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "    plt.grid(True, alpha=.3); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"figures\",\"training_accuracy_curves.png\"), dpi=160); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for key in ['loss','emotion_output_loss','age_output_loss','ethnicity_output_loss'] + (['gender_output_loss'] if USE_GENDER else []):\n",
    "        if key in history:\n",
    "            plt.plot(history[key], label=f\"{key} Train\")\n",
    "            vkey = f\"val_{key}\"\n",
    "            if vkey in history:\n",
    "                plt.plot(history[vkey], label=f\"{key} Val\", linestyle=\"--\")\n",
    "    plt.title(\"CNN Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "    plt.grid(True, alpha=.3); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"figures\",\"training_loss_curves.png\"), dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c821063c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Per-class metrics & MBV2 comparison (if trained)\n",
    "# =========================================================\n",
    "def perclass_metrics(y_true, y_pred, labels):\n",
    "    prec, rec, f1, sup = precision_recall_fscore_support(y_true, y_pred,\n",
    "                                                         labels=np.arange(len(labels)), average=None, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(labels)))\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        row_sums = cm.sum(axis=1, keepdims=True)\n",
    "        acc = np.divide(cm.diagonal()[:, None], row_sums, where=row_sums>0).flatten()\n",
    "        acc = np.nan_to_num(acc, nan=0.0)\n",
    "    dfm = pd.DataFrame({\"class_id\": np.arange(len(labels)),\n",
    "                        \"class_label\": labels,\n",
    "                        \"precision\": prec, \"recall\": rec, \"f1\": f1, \"support\": sup, \"accuracy\": acc})\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dea2d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn = perclass_metrics(y_true_emotion, y_pred_emotion, EMOS)\n",
    "df_cnn.to_csv(os.path.join(\"figures\",\"emotion_metrics_cnn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37026b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MobileNetV2 Test Metrics:\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.3602 - loss: 1.7369\n",
      "loss: 1.7369\n",
      "compile_metrics: 0.3602\n"
     ]
    }
   ],
   "source": [
    "if USE_MBV2 and 'test_ds_mbv2' in locals():\n",
    "    print(\"\\n MobileNetV2 Test Metrics:\")\n",
    "    mb_results = mb_model.evaluate(test_ds_mbv2, verbose=1)\n",
    "    for name, val in zip(mb_model.metrics_names, mb_results):\n",
    "        print(f\"{name}: {float(val):.4f}\")\n",
    "\n",
    "    logits_mb = mb_model.predict(test_ds_mbv2, verbose=0)\n",
    "    y_true_mb = np.array(list(test_ds_mbv2.unbatch().map(lambda x, y: y).as_numpy_iterator()), dtype=np.int32)\n",
    "    y_pred_mb = np.argmax(logits_mb, axis=1)\n",
    "\n",
    "    acc_cnn = (y_pred_emotion == y_true_emotion).mean()\n",
    "    acc_mb  = (y_pred_mb      == y_true_mb).mean()\n",
    "\n",
    "    x = np.arange(2); w = 0.6\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar([\"CNN\",\"MBV2\"], [acc_cnn, acc_mb], width=w)\n",
    "    plt.ylim(0,1.0); plt.ylabel(\"Emotion Test Accuracy\"); plt.title(\"CNN vs MobileNetV2\")\n",
    "    for i,v in enumerate([acc_cnn, acc_mb]): plt.text(i, min(0.98, v+0.02), f\"{v:.3f}\", ha='center')\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(\"figures\",\"compare_test_accuracy.png\"), dpi=160); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0880231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done.\n",
      "Saved:\n",
      "  CNN best model: masked_face_multitask_model.keras\n",
      "  CNN last model: masked_face_multitask_model_last.keras\n",
      "  MBV2 last model: mbv2_last.keras\n",
      "  Sidecar labels: masked_face_multitask_model*.labels.json\n",
      "  Reports: training_log.csv, reports/*_classification_report.txt\n",
      "  Figures: training_accuracy_curves.png, training_loss_curves.png\n",
      "            csv_raw_emotion_count.png, processed_emotion_count.png\n",
      "            processed_gender_count.png, processed_age_count.png, processed_ethnicity_count.png\n",
      "            emotion/age/ethnicity[/gender] cm_*.png and normalized cm_*.png\n",
      "            compare_test_accuracy.png (if MBV2 trained)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Done.\")\n",
    "print(\"Saved:\")\n",
    "print(\"  CNN best model: masked_face_multitask_model.keras\")\n",
    "print(\"  CNN last model: masked_face_multitask_model_last.keras\")\n",
    "if USE_MBV2:\n",
    "    print(\"  MBV2 last model: mbv2_last.keras\")\n",
    "print(\"  Sidecar labels: masked_face_multitask_model*.labels.json\")\n",
    "print(\"  Reports: training_log.csv, reports/*_classification_report.txt\")\n",
    "print(\"  Figures: training_accuracy_curves.png, training_loss_curves.png\")\n",
    "print(\"            csv_raw_emotion_count.png, processed_emotion_count.png\")\n",
    "print(\"            processed_gender_count.png, processed_age_count.png, processed_ethnicity_count.png\")\n",
    "print(\"            emotion/age/ethnicity[/gender] cm_*.png and normalized cm_*.png\")\n",
    "print(\"            compare_test_accuracy.png (if MBV2 trained)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad2412f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- graceful teardown to avoid AtomicFunction.__del__ noise ---\n",
    "try:\n",
    "    del emotion_head, age_head, ethnicity_head\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del gender_head\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del cnn_model\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del mb_model\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5946044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1a30753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151194d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a1ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d6b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa25fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
